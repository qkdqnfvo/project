{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(observe):\n",
    "    # rm_img = observe[20:195,:,:]\n",
    "    rm_img = observe\n",
    "    processed_observe = np.uint8(resize(rgb2gray(rm_img), (150, 150), mode='constant') * 255)\n",
    "    return processed_observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A finish\n",
      "B finish\n",
      "C finish\n",
      "D finish\n",
      "E finish\n",
      "F finish\n",
      "G finish\n",
      "H finish\n",
      "I finish\n",
      "J finish\n",
      "K finish\n",
      "L finish\n",
      "M finish\n",
      "N finish\n",
      "O finish\n",
      "P finish\n",
      "Q finish\n",
      "R finish\n",
      "S finish\n",
      "T finish\n",
      "U finish\n",
      "V finish\n",
      "W finish\n",
      "X finish\n",
      "Y finish\n",
      "Z finish\n"
     ]
    }
   ],
   "source": [
    "char_list = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "for i in char_list:\n",
    "    path = './data/Img/char/train/upper/{}/'.format(i)\n",
    "    org_path = './data/Img/char/org/train/upper/{}/'.format(i)\n",
    "    file_list = os.listdir(org_path)\n",
    "    for j in file_list:\n",
    "        tmp = cv2.imread(org_path+j)\n",
    "        tmp = pre_processing(tmp)\n",
    "        cv2.imwrite(path+j, tmp)\n",
    "    print('{} finish'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 26 classes.\n",
      "Found 130 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir='./data/Img/char/train/upper/'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=20, shear_range=0.1,\n",
    "    width_shift_range=0.1, height_shift_range=0.1,\n",
    "    zoom_range=0.1, horizontal_flip=False, fill_mode='nearest')\n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, target_size=(84, 84)\n",
    "#                     , color_mode='grayscale', batch_size=20, class_mode='categorical')\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150)\n",
    "                    , batch_size=20, class_mode='categorical')\n",
    "\n",
    "valid_dir='./data/Img/char/valid/upper/'\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, target_size=(84, 84)\n",
    "#                     , color_mode='grayscale', batch_size=20, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(150, 150)\n",
    "                    , batch_size=20, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_generator[0][0].shape[1:]\n",
    "output_shape = train_generator[0][1].shape[1]\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(output_shape, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_generator[0][0].shape[1:]\n",
    "output_shape = train_generator[0][1].shape[1]\n",
    "model2=Sequential()\n",
    "model2.add(Conv2D(64, (5, 5), activation='relu', input_shape=input_shape))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "# model2.add(Dropout(0.5))\n",
    "model2.add(Dense(512, activation='relu'))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dense(output_shape, activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "71/71 [==============================] - 5s 46ms/step - loss: 3.2711 - accuracy: 0.0496\n",
      "Epoch 2/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 2.5349 - accuracy: 0.2106\n",
      "Epoch 3/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 1.9842 - accuracy: 0.3624\n",
      "Epoch 4/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 1.3291 - accuracy: 0.5660\n",
      "Epoch 5/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.8958 - accuracy: 0.7128\n",
      "Epoch 6/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.6619 - accuracy: 0.7957\n",
      "Epoch 7/300\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.4799 - accuracy: 0.8582\n",
      "Epoch 8/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.3906 - accuracy: 0.8816\n",
      "Epoch 9/300\n",
      "71/71 [==============================] - 4s 46ms/step - loss: 0.3899 - accuracy: 0.8787\n",
      "Epoch 10/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.2956 - accuracy: 0.9177\n",
      "Epoch 11/300\n",
      "71/71 [==============================] - 5s 70ms/step - loss: 0.2981 - accuracy: 0.9156\n",
      "Epoch 12/300\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.2659 - accuracy: 0.9191\n",
      "Epoch 13/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.1984 - accuracy: 0.9369\n",
      "Epoch 14/300\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.2169 - accuracy: 0.9340\n",
      "Epoch 15/300\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.1916 - accuracy: 0.9426\n",
      "Epoch 16/300\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.1866 - accuracy: 0.9447\n",
      "Epoch 17/300\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.1766 - accuracy: 0.9468\n",
      "Epoch 18/300\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.1693 - accuracy: 0.9539\n",
      "Epoch 19/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.1404 - accuracy: 0.9560\n",
      "Epoch 20/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1287 - accuracy: 0.9603\n",
      "Epoch 21/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1688 - accuracy: 0.9525\n",
      "Epoch 22/300\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1149 - accuracy: 0.9660\n",
      "Epoch 23/300\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.0981 - accuracy: 0.9695\n",
      "Epoch 24/300\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1142 - accuracy: 0.9638\n",
      "Epoch 25/300\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.1073 - accuracy: 0.9688\n",
      "Epoch 26/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.1189 - accuracy: 0.9674\n",
      "Epoch 27/300\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.1313 - accuracy: 0.9617\n",
      "Epoch 28/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0741 - accuracy: 0.9738\n",
      "Epoch 29/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0897 - accuracy: 0.9745\n",
      "Epoch 30/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.1114 - accuracy: 0.9660\n",
      "Epoch 31/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0882 - accuracy: 0.9773\n",
      "Epoch 32/300\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 0.0856 - accuracy: 0.9759\n",
      "Epoch 33/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0949 - accuracy: 0.9716\n",
      "Epoch 34/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0681 - accuracy: 0.9787\n",
      "Epoch 35/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.0986 - accuracy: 0.9738\n",
      "Epoch 36/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0630 - accuracy: 0.9789\n",
      "Epoch 37/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0796 - accuracy: 0.9780\n",
      "Epoch 38/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0818 - accuracy: 0.9787\n",
      "Epoch 39/300\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.0569 - accuracy: 0.9837\n",
      "Epoch 40/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.0821 - accuracy: 0.9809\n",
      "Epoch 41/300\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.0560 - accuracy: 0.9830\n",
      "Epoch 42/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.0781 - accuracy: 0.9766\n",
      "Epoch 43/300\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 0.0585 - accuracy: 0.9837\n",
      "Epoch 44/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0781 - accuracy: 0.9858\n",
      "Epoch 45/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0922 - accuracy: 0.9830\n",
      "Epoch 46/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0700 - accuracy: 0.9823\n",
      "Epoch 47/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0557 - accuracy: 0.9844\n",
      "Epoch 48/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.0604 - accuracy: 0.9844\n",
      "Epoch 49/300\n",
      "71/71 [==============================] - 5s 68ms/step - loss: 0.0881 - accuracy: 0.9787\n",
      "Epoch 50/300\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 0.0407 - accuracy: 0.9894\n",
      "Epoch 51/300\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 0.0853 - accuracy: 0.9858\n",
      "Epoch 52/300\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.0459 - accuracy: 0.9872\n",
      "Epoch 53/300\n",
      "71/71 [==============================] - 5s 70ms/step - loss: 0.0798 - accuracy: 0.9844\n",
      "Epoch 54/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0654 - accuracy: 0.9801\n",
      "Epoch 55/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0890 - accuracy: 0.9801\n",
      "Epoch 56/300\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.0470 - accuracy: 0.9865\n",
      "Epoch 57/300\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 0.0363 - accuracy: 0.9908\n",
      "Epoch 58/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.0791 - accuracy: 0.9844\n",
      "Epoch 59/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0515 - accuracy: 0.9858\n",
      "Epoch 60/300\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.0377 - accuracy: 0.9887\n",
      "Epoch 61/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0698 - accuracy: 0.9879\n",
      "Epoch 62/300\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.0437 - accuracy: 0.9894\n",
      "Epoch 63/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0604 - accuracy: 0.9879\n",
      "Epoch 64/300\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.0561 - accuracy: 0.9872\n",
      "Epoch 65/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0580 - accuracy: 0.9858\n",
      "Epoch 66/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0632 - accuracy: 0.9887\n",
      "Epoch 67/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0746 - accuracy: 0.9823\n",
      "Epoch 68/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0606 - accuracy: 0.9879\n",
      "Epoch 69/300\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.0463 - accuracy: 0.9894\n",
      "Epoch 70/300\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.0754 - accuracy: 0.9887\n",
      "Epoch 71/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0562 - accuracy: 0.9865\n",
      "Epoch 72/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0634 - accuracy: 0.9872\n",
      "Epoch 73/300\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.0342 - accuracy: 0.9929\n",
      "Epoch 74/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.1049 - accuracy: 0.9837\n",
      "Epoch 75/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0617 - accuracy: 0.9858\n",
      "Epoch 76/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0738 - accuracy: 0.9858\n",
      "Epoch 77/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0403 - accuracy: 0.9901\n",
      "Epoch 78/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0711 - accuracy: 0.9901\n",
      "Epoch 79/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0393 - accuracy: 0.9922\n",
      "Epoch 80/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0861 - accuracy: 0.9823\n",
      "Epoch 81/300\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0460 - accuracy: 0.9879\n",
      "Epoch 82/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0590 - accuracy: 0.9894\n",
      "Epoch 83/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0528 - accuracy: 0.9929\n",
      "Epoch 84/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0520 - accuracy: 0.9887\n",
      "Epoch 85/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0365 - accuracy: 0.9915\n",
      "Epoch 86/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0799 - accuracy: 0.9879\n",
      "Epoch 87/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0607 - accuracy: 0.9901\n",
      "Epoch 88/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.0401 - accuracy: 0.9887\n",
      "Epoch 89/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0701 - accuracy: 0.9865\n",
      "Epoch 90/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0457 - accuracy: 0.9929\n",
      "Epoch 91/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.0462 - accuracy: 0.9922\n",
      "Epoch 92/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0618 - accuracy: 0.9872\n",
      "Epoch 93/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0652 - accuracy: 0.9865\n",
      "Epoch 94/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0617 - accuracy: 0.9865\n",
      "Epoch 95/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0775 - accuracy: 0.9908\n",
      "Epoch 96/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0577 - accuracy: 0.9901\n",
      "Epoch 97/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0467 - accuracy: 0.9929\n",
      "Epoch 98/300\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.0583 - accuracy: 0.9922\n",
      "Epoch 99/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0600 - accuracy: 0.9887\n",
      "Epoch 100/300\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.0356 - accuracy: 0.9943\n",
      "Epoch 101/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0858 - accuracy: 0.9901\n",
      "Epoch 102/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0304 - accuracy: 0.9972\n",
      "Epoch 103/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0504 - accuracy: 0.9901\n",
      "Epoch 104/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0638 - accuracy: 0.9894\n",
      "Epoch 105/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0519 - accuracy: 0.9915\n",
      "Epoch 106/300\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 0.0320 - accuracy: 0.9943\n",
      "Epoch 107/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0501 - accuracy: 0.9943\n",
      "Epoch 108/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0560 - accuracy: 0.9901\n",
      "Epoch 109/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0662 - accuracy: 0.9894\n",
      "Epoch 110/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.1065 - accuracy: 0.9851\n",
      "Epoch 111/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0550 - accuracy: 0.9894\n",
      "Epoch 112/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0730 - accuracy: 0.9908\n",
      "Epoch 113/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0379 - accuracy: 0.9908\n",
      "Epoch 114/300\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 0.0658 - accuracy: 0.9908\n",
      "Epoch 115/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0574 - accuracy: 0.9858\n",
      "Epoch 116/300\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.0910 - accuracy: 0.9851\n",
      "Epoch 117/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0800 - accuracy: 0.9879\n",
      "Epoch 118/300\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.0418 - accuracy: 0.9929\n",
      "Epoch 119/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0518 - accuracy: 0.9929\n",
      "Epoch 120/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0476 - accuracy: 0.9915\n",
      "Epoch 121/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0829 - accuracy: 0.9872\n",
      "Epoch 122/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0696 - accuracy: 0.9872\n",
      "Epoch 123/300\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 0.0725 - accuracy: 0.9922\n",
      "Epoch 124/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0517 - accuracy: 0.9908\n",
      "Epoch 125/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0169 - accuracy: 0.9972\n",
      "Epoch 126/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0817 - accuracy: 0.9922\n",
      "Epoch 127/300\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 0.0563 - accuracy: 0.9922\n",
      "Epoch 128/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0611 - accuracy: 0.9887\n",
      "Epoch 129/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0642 - accuracy: 0.9887\n",
      "Epoch 130/300\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.0787 - accuracy: 0.9929\n",
      "Epoch 131/300\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 0.0699 - accuracy: 0.9922\n",
      "Epoch 132/300\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.1039 - accuracy: 0.9837\n",
      "Epoch 133/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0276 - accuracy: 0.9965\n",
      "Epoch 134/300\n",
      "71/71 [==============================] - 4s 58ms/step - loss: 0.0920 - accuracy: 0.9943\n",
      "Epoch 135/300\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.0281 - accuracy: 0.9957\n",
      "Epoch 136/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0520 - accuracy: 0.9929\n",
      "Epoch 137/300\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.0910 - accuracy: 0.9872\n",
      "Epoch 138/300\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 0.0665 - accuracy: 0.9908\n",
      "Epoch 139/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0565 - accuracy: 0.9879\n",
      "Epoch 140/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0411 - accuracy: 0.9901\n",
      "Epoch 141/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0279 - accuracy: 0.9957\n",
      "Epoch 142/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0928 - accuracy: 0.9858\n",
      "Epoch 143/300\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.0809 - accuracy: 0.9865\n",
      "Epoch 144/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.1176 - accuracy: 0.9858\n",
      "Epoch 145/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0290 - accuracy: 0.9950\n",
      "Epoch 146/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0842 - accuracy: 0.9865\n",
      "Epoch 147/300\n",
      "71/71 [==============================] - 3s 34ms/step - loss: 0.0396 - accuracy: 0.9936\n",
      "Epoch 148/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0582 - accuracy: 0.9915\n",
      "Epoch 149/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0769 - accuracy: 0.9922\n",
      "Epoch 150/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.1331 - accuracy: 0.9865\n",
      "Epoch 151/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0783 - accuracy: 0.9922\n",
      "Epoch 152/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0427 - accuracy: 0.9943\n",
      "Epoch 153/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0455 - accuracy: 0.9957\n",
      "Epoch 154/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0916 - accuracy: 0.9908\n",
      "Epoch 155/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0778 - accuracy: 0.9830\n",
      "Epoch 156/300\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.0697 - accuracy: 0.9908\n",
      "Epoch 157/300\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0566 - accuracy: 0.9922\n",
      "Epoch 158/300\n",
      "71/71 [==============================] - 5s 71ms/step - loss: 0.0212 - accuracy: 0.9957\n",
      "Epoch 159/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.1351 - accuracy: 0.9887\n",
      "Epoch 160/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0085 - accuracy: 0.9979\n",
      "Epoch 161/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0535 - accuracy: 0.9936\n",
      "Epoch 162/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0741 - accuracy: 0.9901\n",
      "Epoch 163/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0401 - accuracy: 0.9950\n",
      "Epoch 164/300\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0478 - accuracy: 0.9936\n",
      "Epoch 165/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.0859 - accuracy: 0.9915\n",
      "Epoch 166/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.1242 - accuracy: 0.9887\n",
      "Epoch 167/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0848 - accuracy: 0.9887\n",
      "Epoch 168/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0512 - accuracy: 0.9915\n",
      "Epoch 169/300\n",
      "71/71 [==============================] - 3s 34ms/step - loss: 0.0584 - accuracy: 0.9908\n",
      "Epoch 170/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0753 - accuracy: 0.9908\n",
      "Epoch 171/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0465 - accuracy: 0.9901\n",
      "Epoch 172/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.0877 - accuracy: 0.9872\n",
      "Epoch 173/300\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 0.0829 - accuracy: 0.9908\n",
      "Epoch 174/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0554 - accuracy: 0.9915\n",
      "Epoch 175/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.1056 - accuracy: 0.9915\n",
      "Epoch 176/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0576 - accuracy: 0.9915\n",
      "Epoch 177/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0674 - accuracy: 0.9915\n",
      "Epoch 178/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0613 - accuracy: 0.9908\n",
      "Epoch 179/300\n",
      "71/71 [==============================] - 4s 47ms/step - loss: 0.0323 - accuracy: 0.9950\n",
      "Epoch 180/300\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.0879 - accuracy: 0.9901\n",
      "Epoch 181/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0511 - accuracy: 0.9936\n",
      "Epoch 182/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.1112 - accuracy: 0.9922\n",
      "Epoch 183/300\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.0568 - accuracy: 0.9929\n",
      "Epoch 184/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0276 - accuracy: 0.9957\n",
      "Epoch 185/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0698 - accuracy: 0.9929\n",
      "Epoch 186/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0618 - accuracy: 0.9915\n",
      "Epoch 187/300\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.0885 - accuracy: 0.9929\n",
      "Epoch 188/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.0692 - accuracy: 0.9943\n",
      "Epoch 189/300\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0403 - accuracy: 0.9979\n",
      "Epoch 190/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0355 - accuracy: 0.9950\n",
      "Epoch 191/300\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 0.0453 - accuracy: 0.9922\n",
      "Epoch 192/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0958 - accuracy: 0.9929\n",
      "Epoch 193/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0955 - accuracy: 0.9908\n",
      "Epoch 194/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0955 - accuracy: 0.9887\n",
      "Epoch 195/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0290 - accuracy: 0.9922\n",
      "Epoch 196/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0735 - accuracy: 0.9879\n",
      "Epoch 197/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0352 - accuracy: 0.9943\n",
      "Epoch 198/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0631 - accuracy: 0.9901\n",
      "Epoch 199/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0545 - accuracy: 0.9957\n",
      "Epoch 200/300\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.0116 - accuracy: 0.9972\n",
      "Epoch 201/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0885 - accuracy: 0.9887\n",
      "Epoch 202/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0910 - accuracy: 0.9943\n",
      "Epoch 203/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0455 - accuracy: 0.9908\n",
      "Epoch 204/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0987 - accuracy: 0.9929\n",
      "Epoch 205/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0430 - accuracy: 0.9943\n",
      "Epoch 206/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0577 - accuracy: 0.9908\n",
      "Epoch 207/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0242 - accuracy: 0.9972\n",
      "Epoch 208/300\n",
      "71/71 [==============================] - 3s 39ms/step - loss: 0.0603 - accuracy: 0.9929\n",
      "Epoch 209/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0968 - accuracy: 0.9908\n",
      "Epoch 210/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0747 - accuracy: 0.9943\n",
      "Epoch 211/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0352 - accuracy: 0.9936\n",
      "Epoch 212/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0853 - accuracy: 0.9915\n",
      "Epoch 213/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.1044 - accuracy: 0.9879\n",
      "Epoch 214/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0768 - accuracy: 0.9929\n",
      "Epoch 215/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0492 - accuracy: 0.9950\n",
      "Epoch 216/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0608 - accuracy: 0.9936\n",
      "Epoch 217/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0965 - accuracy: 0.9901\n",
      "Epoch 218/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0574 - accuracy: 0.9950\n",
      "Epoch 219/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0923 - accuracy: 0.9872\n",
      "Epoch 220/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0964 - accuracy: 0.9872\n",
      "Epoch 221/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0569 - accuracy: 0.9950\n",
      "Epoch 222/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0815 - accuracy: 0.9943\n",
      "Epoch 223/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0679 - accuracy: 0.9936\n",
      "Epoch 224/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0620 - accuracy: 0.9915\n",
      "Epoch 225/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.1002 - accuracy: 0.9915\n",
      "Epoch 226/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0904 - accuracy: 0.9957\n",
      "Epoch 227/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 228/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0416 - accuracy: 0.9965\n",
      "Epoch 229/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0418 - accuracy: 0.9950\n",
      "Epoch 230/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0198 - accuracy: 0.9972\n",
      "Epoch 231/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0780 - accuracy: 0.9915\n",
      "Epoch 232/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0824 - accuracy: 0.9915\n",
      "Epoch 233/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0677 - accuracy: 0.9950\n",
      "Epoch 234/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0620 - accuracy: 0.9915\n",
      "Epoch 235/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0718 - accuracy: 0.9950\n",
      "Epoch 236/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0356 - accuracy: 0.9943\n",
      "Epoch 237/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.1530 - accuracy: 0.9922\n",
      "Epoch 238/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0136 - accuracy: 0.9993\n",
      "Epoch 239/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0562 - accuracy: 0.9950\n",
      "Epoch 240/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0614 - accuracy: 0.9943\n",
      "Epoch 241/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0988 - accuracy: 0.9915\n",
      "Epoch 242/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0431 - accuracy: 0.9965\n",
      "Epoch 243/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0761 - accuracy: 0.9929\n",
      "Epoch 244/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0898 - accuracy: 0.9915\n",
      "Epoch 245/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0517 - accuracy: 0.9929\n",
      "Epoch 246/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0217 - accuracy: 0.9986\n",
      "Epoch 247/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0387 - accuracy: 0.9979\n",
      "Epoch 248/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0809 - accuracy: 0.9901\n",
      "Epoch 249/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0191 - accuracy: 0.9957\n",
      "Epoch 250/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.1346 - accuracy: 0.9915\n",
      "Epoch 251/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0675 - accuracy: 0.9943\n",
      "Epoch 252/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0735 - accuracy: 0.9929\n",
      "Epoch 253/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0958 - accuracy: 0.9922\n",
      "Epoch 254/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.1193 - accuracy: 0.9901\n",
      "Epoch 255/300\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.1084 - accuracy: 0.9901\n",
      "Epoch 256/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0291 - accuracy: 0.9979\n",
      "Epoch 257/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0864 - accuracy: 0.9908\n",
      "Epoch 258/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0662 - accuracy: 0.9922\n",
      "Epoch 259/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.1540 - accuracy: 0.9887\n",
      "Epoch 260/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0775 - accuracy: 0.9922\n",
      "Epoch 261/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0115 - accuracy: 0.9986\n",
      "Epoch 262/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0410 - accuracy: 0.9957\n",
      "Epoch 263/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0279 - accuracy: 0.9965\n",
      "Epoch 264/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0290 - accuracy: 0.9965\n",
      "Epoch 265/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0554 - accuracy: 0.9965\n",
      "Epoch 266/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0368 - accuracy: 0.9950\n",
      "Epoch 267/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0928 - accuracy: 0.9894\n",
      "Epoch 268/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.1018 - accuracy: 0.9915\n",
      "Epoch 269/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0192 - accuracy: 0.9957\n",
      "Epoch 270/300\n",
      "71/71 [==============================] - 3s 34ms/step - loss: 0.0827 - accuracy: 0.9950\n",
      "Epoch 271/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0401 - accuracy: 0.9957\n",
      "Epoch 272/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.1242 - accuracy: 0.9908\n",
      "Epoch 273/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0801 - accuracy: 0.9908\n",
      "Epoch 274/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0341 - accuracy: 0.9958\n",
      "Epoch 275/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0304 - accuracy: 0.9965\n",
      "Epoch 276/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.1347 - accuracy: 0.9908\n",
      "Epoch 277/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0214 - accuracy: 0.9972\n",
      "Epoch 278/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0567 - accuracy: 0.9972\n",
      "Epoch 279/300\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.0249 - accuracy: 0.9986\n",
      "Epoch 280/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0222 - accuracy: 0.9979\n",
      "Epoch 281/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0454 - accuracy: 0.9972\n",
      "Epoch 282/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0399 - accuracy: 0.9965\n",
      "Epoch 283/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0400 - accuracy: 0.9972\n",
      "Epoch 284/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.1077 - accuracy: 0.9936\n",
      "Epoch 285/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0105 - accuracy: 0.9986\n",
      "Epoch 286/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0486 - accuracy: 0.9957\n",
      "Epoch 287/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.1029 - accuracy: 0.9894\n",
      "Epoch 288/300\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.1492 - accuracy: 0.9901\n",
      "Epoch 289/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0877 - accuracy: 0.9950\n",
      "Epoch 290/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0210 - accuracy: 0.9965\n",
      "Epoch 291/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0672 - accuracy: 0.9950\n",
      "Epoch 292/300\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.0427 - accuracy: 0.9972\n",
      "Epoch 293/300\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.2196 - accuracy: 0.9801\n",
      "Epoch 294/300\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 0.0496 - accuracy: 0.9943\n",
      "Epoch 295/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0417 - accuracy: 0.9957\n",
      "Epoch 296/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0363 - accuracy: 0.9979\n",
      "Epoch 297/300\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 0.0788 - accuracy: 0.9922\n",
      "Epoch 298/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0205 - accuracy: 0.9950\n",
      "Epoch 299/300\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.0883 - accuracy: 0.9936\n",
      "Epoch 300/300\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 0.0392 - accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "# steps_per_epoch = len(X_train)//batch_size\n",
    "steps_per_epoch = 1300//20\n",
    "history2 = model2.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=300,\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABiHklEQVR4nO2dd5hbxbn/PyOtVtubd917N8bdphdTEmogBQImBUIKIQECuQkhuSmk3PT+SyAhgUByKcklgZAAgeDQEopxw9jGxsa973q9XdpVmd8fc0bn6Kistmi1q53P8/iRdHR0zhzJ+533fOedd4SUEoPBYDAMHzy5boDBYDAYBhYj/AaDwTDMMMJvMBgMwwwj/AaDwTDMMMJvMBgMwwwj/AaDwTDMMMJvMCRBCLFLCHFurtthMGQDI/wGg8EwzDDCbzAYDMMMI/wGQxqEEH4hxE+FEAesfz8VQvit92qFEH8XQjQJIRqFEC8KITzWe18QQuwXQrQKIbYKIc7J7ZUYDDYFuW6AwTDI+W/gJGAhIIG/Al8GvgL8F7APqLP2PQmQQohZwA3AMinlASHEZMA7sM02GFJjIn6DIT0fAL4hpTwipawHvg58yHovBIwBJkkpQ1LKF6UqfhUB/MBxQgiflHKXlPLtnLTeYEiCEX6DIT1jgd2O17utbQA/ALYDTwshdgghbgOQUm4HbgZuB44IIR4SQozFYBgkGOE3GNJzAJjkeD3R2oaUslVK+V9SyqnAJcBntZcvpXxASnma9VkJfG9gm20wpMYIv8GQngeBLwsh6oQQtcBXgf8FEEJcLISYLoQQQDPK4okKIWYJIc62BoGDQACI5qj9BkMCRvgNhvR8C1gNbADeANZa2wBmAM8AbcDLwB1SymdR/v53gQbgEDAS+OLANttgSI0wC7EYDAbD8MJE/AaDwTDMMMJvMBgMwwwj/AaDwTDMMMJvMBgMw4whUbKhtrZWTp48OdfNMBgMhiHFmjVrGqSUde7tQ0L4J0+ezOrVq3PdDIPBYBhSCCF2J9turB6DwWAYZhjhNxgMhmGGEX6DwWAYZgwJj98wvAiFQuzbt49gMJjrpuQNRUVFjB8/Hp/Pl+umGAYBRvgNg459+/ZRXl7O5MmTUfXPDH1BSsnRo0fZt28fU6ZMyXVzDIMAY/UYBh3BYJARI0YY0e8nhBCMGDHC3EEZYhjhNwxKjOj3L+b7NDgxwm8wGAyDkcadsPIb0Hqo3w9thN9gcHH06FEWLlzIwoULGT16NOPGjYu97urqSvvZ1atXc9NNN3V7jlNOOaW/mmvIVzb9BV78EURC/X5oM7hrMLgYMWIE69evB+D222+nrKyMz33uc7H3w+EwBQXJ/3SWLl3K0qVLuz3HSy+91C9tNeQxGx+B8SdA1YR+P7SJ+A2GDLjmmmv45Cc/yYknnsitt97KqlWrOPnkk1m0aBGnnHIKW7duBeC5557j4osvBlSnce2117J8+XKmTp3Kz3/+89jxysrKYvsvX76cyy67jNmzZ/OBD3wAvTjSE088wezZs1myZAk33XRT7LiGYUDDNjj8Bhz/3qwc3kT8hkHN1/+2ic0HWvr1mMeNreBr75rb48/t27ePl156Ca/XS0tLCy+++CIFBQU888wzfOlLX+LPf/5zwme2bNnCs88+S2trK7NmzeL6669PyKVft24dmzZtYuzYsZx66qn85z//YenSpVx33XW88MILTJkyhRUrVvT6eg1DkP1r1OO0s7NyeCP8BkOGXH755Xi9XgCam5u5+uqr2bZtG0IIQqHkPuxFF12E3+/H7/czcuRIDh8+zPjx4+P2OeGEE2LbFi5cyK5duygrK2Pq1KmxvPsVK1Zw1113ZfHqDIMK7ev7SrJyeCP8hkFNbyLzbFFaWhp7/pWvfIWzzjqLRx55hF27drF8+fKkn/H7/bHnXq+XcDjcq30Mw4yoJfze7My0Nh6/wdALmpubGTduHAD33ntvvx9/1qxZ7Nixg127dgHwxz/+sd/PYRiEHFgH910CXR3qtSc7sbkRfoOhF9x666188YtfZNGiRVmJ0IuLi7njjjs4//zzWbJkCeXl5VRWVvb7eQyDjH2rYefz0HpQvc6S8AudQTCYWbp0qTQLsQwf3nzzTebMmZPrZuSctrY2ysrKkFLy6U9/mhkzZnDLLbf0+njmex0CvHwHPPVFWPpRWH03fHE/+Mt6fTghxBopZUJ+sYn4DYZBym9+8xsWLlzI3LlzaW5u5rrrrst1kwzZJmJNEAxbdZWy5PGbwV2DYZByyy239CnCNwxBdDZPyHj8BoPBMDzQEX8oCAjweLNyGiP8BoPBMFiIdKrHcCBr0T4Y4TcYDIbBQ8zqCWbN3wcj/AaDwTB4iFk9HSbiNxgGkrPOOounnnoqbttPf/pTrr/++qT7L1++HJ1ufOGFF9LU1JSwz+23384Pf/jDtOd99NFH2bx5c+z1V7/6VZ555pkett4wpHFm9Rjh7x3PbD7M3zccyHUzDEOMFStW8NBDD8Vte+ihhzIqlPbEE09QVVXVq/O6hf8b3/gG5557bq+OZRiiOK0eI/y94/5Xd3PXCzty3QzDEOOyyy7j8ccfjy26smvXLg4cOMCDDz7I0qVLmTt3Ll/72teSfnby5Mk0NDQA8D//8z/MnDmT0047LVa2GVR+/rJly1iwYAHve9/76Ojo4KWXXuKxxx7j85//PAsXLuTtt9/mmmuu4eGHHwZg5cqVLFq0iHnz5nHttdfS2dkZO9/XvvY1Fi9ezLx589iyZUs2vxpDpgSaoOVgzz8Xi/gDWfX4s9alCCHuAS4Gjkgpj7e21QB/BCYDu4D3SymPZasNHiGIDoGZyYY0PHkbHHqjf485eh5c8N2Ub9fU1HDCCSfw5JNPcumll/LQQw/x/ve/ny996UvU1NQQiUQ455xz2LBhA/Pnz096jDVr1vDQQw+xfv16wuEwixcvZsmSJQC8973v5eMf/zgAX/7yl7n77ru58cYbueSSS7j44ou57LLL4o4VDAa55pprWLlyJTNnzuTDH/4wd955JzfffDMAtbW1rF27ljvuuIMf/vCH/Pa3v+2HL8nQJ346Dzpb4Pbmnn0u5vEHwFfc/+2yyGbEfy9wvmvbbcBKKeUMYKX1OmsIIYhGs3kGQ77itHu0zfOnP/2JxYsXs2jRIjZt2hRny7h58cUXec973kNJSQkVFRVccsklsfc2btzI6aefzrx587j//vvZtGlT2rZs3bqVKVOmMHPmTACuvvpqXnjhhdj7732vWqxjyZIlsaJuhhzT2cs1JGJWTwA8QzDil1K+IISY7Np8KbDcen4f8BzwhWy1QQhMxD/USROZZ5NLL72UW265hbVr19LR0UFNTQ0//OEPee2116iuruaaa64hGAz26tjXXHMNjz76KAsWLODee+/lueee61NbdVlnU9J5kBDpw2+gI34ZySuPf5SUUhtfh4BR2TyZR2Tz6IZ8pqysjLPOOotrr72WFStW0NLSQmlpKZWVlRw+fJgnn3wy7efPOOMMHn30UQKBAK2trfztb3+Lvdfa2sqYMWMIhULcf//9se3l5eW0trYmHGvWrFns2rWL7du3A/CHP/yBM888s5+u1NDvNO3u/WedC6vnkfDHkKosaMpwXAjxCSHEaiHE6vr6+l6dw3j8hr6wYsUKXn/9dVasWMGCBQtYtGgRs2fP5qqrruLUU09N+9nFixdzxRVXsGDBAi644AKWLVsWe++b3/wmJ554IqeeeiqzZ8+Obb/yyiv5wQ9+wKJFi3j77bdj24uKivjd737H5Zdfzrx58/B4PHzyk5/s/ws29A/19kB+j71mHfEDeLMn/Fkty2xZPX93DO5uBZZLKQ8KIcYAz0kpZ3V3nN6WZf70/WvZeriVZz5roqOhhCkfnB3M9zpA/Psn8Mzt6vmXDkJhD5ZPvGu5WowFYNwS+Pi/+tSUwVKW+THgauv51cBfs3o24/EbDIaBpmGb/TwU6Nln46yeIViyQQjxIPAyMEsIsU8I8VHgu8A7hBDbgHOt11nDI0QaM8lgMBiyQOsh+7kur5wpTqsnix5/NrN6Uk1zPCdb53TjMRH/kEVKiRBmdL6/GAor7eUNgUb7ebiHmV8D5PHn9cxdNbib61YYekpRURFHjx41YtVPSCk5evQoRUVFuWvEwddhz6u5O/9A0tEIhdZyiT2O+AcmqyevV+ASmIh/KDJ+/Hj27dtHb7O5DIkUFRUxfvz43DXg2W9D22H4xHO5a8NAETgGFeOgYau1oEoPiLN6huAErsGAEAKj+0MPn8/HlClTct0MQ38SCkBXe65bkX0iITVrd9wSS/j74vFnZ/UtyHurx3ibBsOgIBLqefQ7FAlYpccqxqnHvmT1mIVYeofx+A2GQUI01PPodyjSYQ3sVlrCH+6p8A9MVk9eC7+p1WMw9BMH1kGwh5UmnURCPc9wyZRwF6z9fc9nyWYDndFTMVY99iTij0Yh6qjzMxTz+AcDQgiTxm8Y+hx9G7Y8kbvzR6NwzwXw6l19OEZYRfzZCMR2PAeP3QgH1/f/sXuKjvgrrIH0Hgl/KP618fh7h/H4DXnBqt/Ao8mXfRwQwkFlWbT3IcsqEgIZjfew+4uQNWg8GAaPAy6rpyfC77R5wHj8vcV4/Ia8INIJ4c7cnV+LV6ercmjTnsztHx3NZsPn199NLr8jTUeGVs/B1+E5V+ECd6doPP7eYWbuGvKCSCjRBhhItFi7Fxf5/aXw/PczO4auUZ8Nnz8m/D0cSM0GgUbwFoK/Qj2matMDV8Bz37E7CkiM+I3H3zvUClxG+A1DnGhEeeS5CmK0WLuj+45G6Dia2TGGU8RfXKMySwqKU0f8haXq8ahdfjtR+I3H3ytMjTZDXqAzPbLhj2dCLOJ3WT3RcOYRfGxJwSxE/BFL8HuaM58NAsegpEY99xXDlsfhpV8k7lc1UT02OoXf9fsaj793eMzMXUM+EBP+rvT7ZYuYx++yeiJdmUfZsYg/C+KsO59spYv2hMAxFfED+IqgeS88/d+J+5VbYwBHt9vbEiJ+4/H3CuPxG/ICLZq58vmTRfxS9iw3X0ez2fDhw5ZgDgbh72iEkmr13JdmARZpzTlIK/ymVk+vEGbpRUM+EI2ox5xZPZZYBx0RfzQCyMSI/9FPQ9UEWH5b/PZsWj1a8AdDSYhAox3xJ/PoD22Eva/YIh8n/AOXx5/nwp+78TCDod/IucdvCb9OKy3w23cf7ih797+hfWb8NimzO7gbGSQRv5RWxG8Jv3NBFimVIP3KWqt5zrvU49Ed9nsmj79/MB6/IS/Qgp9rjx9suycmtq6IP9icuE3fsUBm4ty8Xw2KZspg8fi72lQHpyN+54Q3d6etv6NQu6Njtb5TbREZj793GI/fkBfoiN9Zx2UgcQq/TulMlpcvZQrhd4heJhH/6nvgjx/M/A5nsHj8OidfR/xO3G3rbLOf6xnH+nqN8PcNgfH4DXlAzOPPVcTvEGud2ZMs4u9sVYOWbpFzCngmPnzgmDpOpnMEUnn8oQA8+iloO5LZcfqKLtdQbA3u6swdSOwMnRlSXa67qEIj/H3CY/L4DfnAYPH4wbZ6knn8+m4gIeJ33KlkEvHrc7Q3ZNa+WCfkyhg6vBnW3w+7X8rsOH1FR/za6rnuBTjtFqttwXjLyzlQHov4tdVjTe4ywt879ApcplCbYUijRTbXE7jAFqxYeqZD5GPCnybiz8SO0dFwRxrhP7wJ7jpLtSfm8bs6nLDLO8+Uztbefdd6ERZt9ZTVwcjj7LY5Pf/OFvD61fMEq6dYPZrB3d7hEQIwmT2GIU7M48+R8DvFOja4mybidwttTz3+TCL+fa/BgbXQtNsxUOqK+FN1CN1x5ynwcpLZtt3hjvhBZUDptrQetLd3ttodRJfl95vB3f7B0n3j8xuGNoPB4y8oUs/dHn+ky46sMon4M/H49V1FOo9fn6urPXWGUagX2T7RqKo66qyhkylujx/s7y3c6UrvjNgdRKdL+I3H3zc8lvAb2TcMaWLpnDnM6ikbqZ5rUXZG8VpwM/L4M5i5qzuXdPX/Y8Lf5ojsU0T8PekwdfTdm9XGOhrBXwleh2A7I/6WA/H76w6iy7WeQFGlejTC3zuEFfKbiN8wJIiEk3vLubZ6QgElaAVFjog/iW+fMuJ3CG8mJRtiwp/G6tEdUFe7I53THfEHkm/XRKPwpw/DnlfsbVp8g03dt9NNwFGuQROL+IPxET84rB7rnG1HVClnfSdgPP7eYTx+w5Di16fDN2sTtw8Gq8dXDP7yFMKvI/4m9RgNx9+d9MTqkdL2+NMN7sYi/g5HOmcPPf6uVtj8V9i+0rGtjxG/098HR8TfmXg9bo+/vQFKR9qCb0o29A7j8RuGFEc2J98+GNI5fcVqcRH3zF1IXq8/0glv/EkJX9Ukx7G6GdwNBezrbc/E429L4/E7Sk0kQ3+fTkHW1xdoSt/OZAQaoWRE/DYd8Uc6E4/pLwfhdQj/EZUJpC2efFuIRQhxixBikxBioxDiQSFEUTbO44kJfzaObjBkkdZDKmURcpfOWb9VReihgMo08Zc7PH5HRO/2+EFFv49eDw9fm9wW2vVvWHe/vf3gBlhzb3wF0Iwi/vbuPf5wijsl3WE4xxJiVk8WIv5gk+o8NV4/FJbZ52yvh9I6R8SfRx6/EGIccBOwVEp5POAFrszGuWyrxyi/YYjxo1kqrRBy4/F3tsGvTof1/2tH/EUViVk9kDzif/1B+7lut6/UjvhX/w6e/ba9z58+BH/7jErTBDWmkM7j70zi8Sebuetsn5uY8DvuLJxWTzSa+vzJcC7ConF6/MFmKBvleM+vVuLS52yrV1aPjvTz0OMvAIqFEAVACXCgm/17hT24m42jGwwDRC48/kCjsifa6lNYPWmyegDW/a969FfY+/rL4uvqdDnq1egxgResNXxrJqs2OGe7Okka8bsEPpbV0wOrR0ffSLuUQiZEQqozSoj4HemcgaZ44ff6LOFvV2Mb7fXK6tFZQfm09KKUcj/wQ2APcBBollI+7d5PCPEJIcRqIcTq+vo0aV1piKVzmojfMJTJRTqn9qO72hyDuxWJM3fBFlinh928Vz12tthRvq/EUeqhU21vPaxsHp2zf/B19ajr3MRNEGuBTY9Yz5vt40dDyhaREddAso74u7N6LOF/4+H4cZae+PzuWbsaZzpnsMlOiwVl9fjL1N1VsEldR2meevxCiGrgUmAKMBYoFUJ80L2flPIuKeVSKeXSurq63p3LejQRv2HQ47QV3IFKLpZe1Bk6Xe0uq8dVqweUiEejcGwnVIxX26TjetoOq8fC0vja+ZEuuP99KpspHIApZ9qf0QLptG/W/QH+7xpo2GbfLWjB1bnvzo4itgh7ML42jka3JdCo9v3zx+Cl/+f4Dnrg83ckmbwFdlmGUFB1JOWj7fcKCm2Pv80Kbp1WTz55/MC5wE4pZb2UMgT8BTglGyfyeIzHbxjkbHsGtj4Zb3u4BScXHn+clRKAAkc6ZzSamJt/bKe6hvFL7O06atf5676SxBo/R7bY+y9yxH8x4XdkAR15Uz3uW21vcwu/s6PQg73N++AH02DHc/HX6LwTaNoDyPjreuwG2PoP9Xzd/bDrP6REz9p1R/zeAiXggUZ1RxIX8RfaHr8eYC5zDO7mmce/BzhJCFEilAl/DvBmNk5kPH7DoOffP4bnvx+fzeKc6BONEpt7PpBZPdrmaLdKGvvLrIwUaaVQOmynP34Q7jhZPR+31N5ePVk9tlg1agpLElfLqplq7z/jnfZz7YU7I/iGt9SjHgAG2yIqqkrcX3cCx3ap87rLMDhFvnEHCRx8HR68Qj1/+svwyh2J+8TakSLiB+Xz69+0uMYxeOu3PX79PcdZPfnl8b8KPAysBd6w2nBXNs5lPH7DoKezRf3hxwm/I9fBGeUPpPBrq0cLlr9cWT1gVa902U6RThAeGLvI3lYzxTqGJfy+0sSIXwvehBOhuMr+bKll74Y6YMfz8OszYP9atS1O+C3BTWr16LWCrWvpdNk93Qk/QMU4db2BxvQlJGJ1epIswuIttO2uokp7wDdm9bSpzglUh1c1QX1XyY7VT+Qkq0dK+TUp5Wwp5fFSyg9JKXtYPi8zBCbiNwxyOlsThV9HyBAvTt15/HtegV+e6MhM6QPa6tGi7a9Q4g/2gKqbEdPjxbvaEn4ter7ixIg/cAxmXwwftfI73vk/UDvLPlcoCP/+iYq+9TkPbVCPJbWOiF9bPY5cfh3x6/EGt4Xm7Egbd9rPSxyzp+tmQdPe+OtIRqrBXVBCrz9bXGUP+Hot4Q82q/TW8cvUBLBp58AXdsZ/l/1MnpdsUI/SlGkzDFaCLSric0ajzvK9ztmo3S29uH8N1G9JrAnTG7TVo8WyqFLl1kPqevXjl9mDmQBVEwFhX0+c1eO4LuekplNugBtW2TXpwwHrOM5jWlSMVb65bh/EC797QleC8Ds60mMO4S8fYz+PRuwMpdbD8QPvj3wSfjgT1tyn7jw8PiXkbgr86rOgLKmY8FtWTzioykuferMqNyCEvU+WyHPhNxG/YRCj69J0tbmsHofwO4Wsu4hfi3V/rD3rLlLmL7ej8GBLovBf/Xe44PvxglVcpTxvHZX7SlX0HY3Et9GfTCwtOyQUiJ/INecS9egtVNG4Rg+aOjtQ94Qud2ZPKqvHX04sJzAUsAZ+UR2J83fa8riK5F/7rVWuocauE+O+lpCj8qb+jgoKlTVWNgpOvB5mXZj42SwxPGr1GOU3DAQ7noO62fEpe+kIB237wll73pk/7hRILbbrH4Dnvgs3rQePI3bTEW0mNe+7wx0d+yvsP6jOZiWaHp/d/jELlIA7bSZ/OZTW2v63rjMfCbki/vLE8+vFSEIBNQ4w/gRYfpsSytI6OP59SnA1ejA47rvrLuJ3dF7HdjvaUwZfOwYPXaVEv8nxXtsRNdbR0Wh3Ms171Z1IKk/e3RnqTs1bCLMvVP8GmLyO+IWpzmnoC8EWuPudqmaNk3AXfHs8vP5Q/PbfXwo/OT7z46fK5JGO2arJhP/IZiVG7sFGHaVnUvq4O9yTl4oqbEums1XZTk5B0wO/zm3+iviiZVrMI53xs2mTCr8j4m87ojKEpp+jourTblYDoE5bRXe2zjuVhIg/hdVTWBY/ZlFYqjo5X4nqyLTHD7ZXr/9PTDpN+fv1W6DCYRE50UKPsMpbOzz+HJHXwm88fkOfOLYT9r5qzybVBJvVdP6/f9bepqOLaCj1TFE3qeyduIVLHOKlxUmv2NTqqnSixbpfIv6m+NcJVk9X8glGccJfHi/8hdYi4qFA/ASvZL54LOLvsEoZjEzcRx8PUkT8rpyRVFk9FWNdx7XaU1iizt+0B8qsjiUm/Nb8gxnnqsej29WgdDL0d1JUoe7QYlk92fXx05Hnwm88fkMf6LImDyUs4q3rvztsDec+u/+d2fGdEWhc7r4z4nd6/Jbw68lezuwf6N+I3x0dF5ZbgiiUgEa6kkesXpfwl+oMGeFYvtFVA8c5uKvR+3YcVeJbmmT2vlP4R0xXYwg6uwYyt3r0YK5uu+7gfKWqk2o5AOMWq21tVvppw1uqc5p0qn28ulTCb13LqHnWaxPxZxVTj9/QJ/SsUXeRr2TLBzotmbefzez4qSJ+56BjKInVo310d8Tfnx5/oMkR+ZarSNXjgdoZ6voiYTWzdN7lcP537c95PLagOSN+b6E9E9UdeSe1eqysHj2w6ixuphGWfJ14vbKAiqsci8FEEgfDU1k9OuLXYwdTzrCu27J6gk1qopmnANqsDrp+q/ounGsNpBJ+fac2yZrk5vT4c0SeD+6akg2GPhATflcGS7KI2in8elJRd2Qi/OFkVo/1udZDqm7N+gfgnK86snpc7etqh//8DE7/nMok6Y5QQHV21ZOhYavt3wMs+xg8easasPX64H2/Tfx8QZFaYMTrs3PivT5b6BIi/iRWj9enhFYPupYlifjnvluNhyz8gHpdVJWY2aQnSIH6PSMhuwPSv6sW/qIKuOwe+/i+EnX8cER1KqUj7bTM5n1K6Evr1J1CpFMN7CfjoDXvYKIl/Pp7MFZPdjALsRj6RKo1W+N8d8uWiasi2ZTZ8Z2RrzOrJ5xC+HWH4LR6fn2GKvvQ0Wif1x3x7/oPPP892PgwfHMkNGxP3y593dpXd1oxC69Swt64I3X1SG+hHcVrq8dT4Ij43cKfJOIHVR9IZ9SUJvH4/eWw5Br7uM6IX38HOr9f40zpjHQBwvbv3e3Q4wygOpXaGXDoDfW6o0Fdm8cDleNVB5Bs8pbeF2DCCdZ15T7iz3PhN1k9Q463noadL+a6FQptqbgtA2fhMO35OjuHTKs6ugVQE2f1OD1+a9DXObir29LV2v1KVPVbVGTatCt9u/TgshZNpyD6yx2eeArhKiiyP6PFMC7ib4vfP5nHD8ruadmvnicb3HVTVKWi6/+3FOrftLc5cXbKepyi1LKj3MJf6BL+iSfBkU3qrqKj0b6bGbfEjuaTcc0TcN637eMPAo8/r60ej/H4hx7Pfkv9QU05PdctcazZ6hJ+ZxTesl+l8Tm3uT3sVKTaL5XV4474nWmmugMCO9oNBVQnqj+no91Ui49r9F2MFqoilzCX1qqMJ28K+SjwO4RfR/xprJ5kWT2gUjplFBDxZRRSUVytOsCjrbDtn1bbdcQvABn/nUdCqk362O4OyOcYPC6uUvWEZNQ6trTvZt7za0iXOTj5VPVPY7J6sotdndMI/5Chq717YRoodNZOqkW8QXm9zn2KazKP+N0zSfVAaDLhLyhKTOfU0TDE15EJB5T4/3QePHC5XdtGt+vwZri9Ena/lLxdCRG/SxBjvn0GEb8WR29BzwZ3QVk9oL6XVJ2ME2dtm4Pr1aO+Bn3HELcgfJdqk25j2oi/UpWkEB7Y+rjdLrAGvntQSVMLfhbr7XdHfgu/9Wh0fwihBxYHA6kifqfwa/HVAl0+umdWjzPPXQ8yRrrsjBUdvfuKVYQqrbLIzs9BvPCHgrDtKXuClx5s1u3aYWUdrXcsdu5ETyDTgu8WRG2NpPL4J50Mk6wlNkoc+7ojfn+lGgTWGTxu9PZMbB6It3X2vKoeqyaoR/3dJgh/oZ0q2p3HX1ShBnC3r1TbSjO4C0nGhBNhxnnJyzsMEHkt/MbjH4IMpohf5/EnWD0O4ddCottcNlJtc/6n2782vvqjprNVRZLaUtCrV4W7HGu1WucqsIQ/1AFIOPkGuHkjvP/36n2n1RMOxGcWORcQB7tT6XKMVTjRVo+2eBKsHksoU0XhF/0IzvqSeu4rVtfn9dkdhRb+kmqV0ZNKALXwJ8vhT4Yz4g8H1HknnqReV1odQP1b6m5nw59sq6e4RtlEev2A2PldET+o+QL6jiUT+ykZx10CH/hT7z7bT+S3x2/9/zZWzxAiFBjYJQbToQdO3TNxnVkz2nbREX/ZKOUDd7XB+gdh5Gy4713qvdtddwKdLdYC5m3KVnJG/AV+df64iL/LPp+/XEWzuriYO+J3ruilhTZB+FOUb44JvyV27gFSLXiZzhcoHWFF/C7hr5udvpKo7vyS5fAnQ7ji2MmnqTkIYOfha5tmzX3q7szrUx3YjWsTLS231QMwYprjunop/IOAvBZ+4/EPMaIRZfP0V8Tf2aaW65uwrHef724CV8kINZgI8RE/KP/+yc+nP36gyVrHtkUVIqscZ52vy56VqiN+X4nKSOlyCD/YfrFes7W4OrGKpFv4nXntydBWT2EZXH5fYsaKFrxMLa2SWkAmWj3v+KZKhUyFjrgztXo040+Afatg6nJ73oK/XC2qcniT1aaa+NnHyVIx9fkLiuzaQc4Vw9x22xAir60es9j6EKMrxWBqb3nsRrj73HgbpCekzOoJKG+6qCox4i9NMoiYirZDKjWysFQdT0e2OuKHJBG/JZo6E0bvp9MUi2tUu50pk/q5tiic6+kmQw/uegrUJKlyV8StI/5Ms5cmn6aWZNQiG+u8yuKjajdabDO1ehZ9CC74AVz1R1hwFcy7zC7DUFimKmjq37JkRPxkrmToztd5x1NjRfxFlVldEzfb5LXwe2LeoVH+AeWtpxOrO2ZCTGj7Sfh1Ia10Kycd2gjfGh1fgVET64iSDO76SqwyxEmsHuh+EpeUyuYoG6VEqWyU7YFHQg6PXwt/kdqu26Rnu2ph0993cbVqX1eSiF8fS2cTpYr4tdWTKlNFD+5mGvG/85tw0Q8Ts3qcdX2S0dPB3YJCOPETKnp/z53qc7pjLCy1fX5Q4wqp6g25z++cBKatnt76+4OEYSH8JuIfQDpb4YH3w4Y/9vyzoRRC21t0pOZcyMPNkTdVBN+cRPhDKQZ3QwElxIXliXcpWqS6WwUrcEwdt3yM8vZrp9tCKyO2YMWEv1TtrzuaQpfVE2xSEbq/TH2ms9XuPJydANjC29WeXLy11ZMq3TDm8afoOFLhtnq6y2Mv6KHwJ0OLdsmIeFupqz0D4bcifuegcdkotX0I+/uQ98KvHs1CLANIuBOQvVv3tSuFp95b9B9s2rVSreyXZKtWpRL+cFCJkr9Miejd77Q7Oh3xdyf8+v3y0XDxT5SX7sxuca5ABcpu6WqzUzS1DRET/mZ1F1JQrOyhTkfKp3vClL7W5r3w3Ymw+a/x7+uIX6SK+HspegnCX5R6X3BYPX0Q/hHT4CNPwszz7NROUN9Pd1aPt0C12RnxC6EWnXF6/UOQvB7c1Sa/0f0BRBe+SrYma3c4PXUp+57nrCN+ZwE0NzrtMdm4QqqyzKEOZQMUlql6OR2OOwrtR7vP6Y4s9fvlo21hcQqt3l+LtF5rVs/W1VZPLKpvUwLpK7IHd0tGqHkG3a7VuxaOu9R+HbN6UsSF2gLp6QQknf7Z2WoVcevm870d3HWj5xQ4rZ6uNvX/LNXkMWcb3FlNVz2U08lX/cHQbn03xPL4jcc/cOjZpb1JyXTWt3cOcPYWbZ20pon4dXG0pBF/qglcQSWw/rJ40S8oskXcLfzOzLLm/fZsWucyjU5P3e3x6/K/DW+pRz246+xQfMVKqHQ6Z6aC6VzAHOIHd1Nx5QNQOzOz42ucnZmzHEIqRs9T//rLT692lFDuarPz+NMx992JWU3uwm9DkOEh/Eb3B46IS/hDQfXHlSp6dOKcERsO9l34daTelsZ2CaSI+CNhuyNKltXjK0msMVPgVwOMBcWJi6REQ2rQu7QWfnOWvb3MIfzOiN+d1aOFXw9YF7oiflDCX6Ajfg+MnJP8mt04V8MC2+NPZfUAzL4os2M7cYpsJr/tnHepf/1FzVTVYa3+nbK5pOw+M+ddP+u/8w8ihofHb5R/4NDRYqQLolH42XxYe19mn3WOCyQb4H3xx/DI9Zm3RUfLaSN+S/g7W9VszlAQ3noKvlkbPys32GJHEKGAEtgE4bdEuKgyub3010+p8shOnOmMSSN+qzPUUfmxXWocQdskTuEqKFLirz3+osr04q1xd3rRbgZ3e4vHa0+y6s7fzxazL1J3Qp1taiwphxUyc0leC78wHv/Ao6PjSJcS3rbD9uzS7nBmiSQb4N32T3jzscxv4bTwtx1SaZsPrkjsUHTEv/N5+MvH4RdL4Y8fJC4FuO0wfHcC3HGS6gxCQSWw7gVEYmurphD+9vr4pQHdiCTCryN+f7lK1QQYu8jxGWGnRfpKHBF/q/pMJpG1/p7aj6rvtrt0zr4QW4Qkh4JbWKoynTKxevKUPBd+M3N3wHFaPVpQnOUD0hFn9SQR/ua96ljpsnScOCP+Xf+GrU8kCrKO+NuP2udwZ2zEyiBvgY1/jh/cdeKM+HUndskv4Nzb48+nBd5p80C8HeZO5/QU2LV8xi5Ofl5fkV3KOBpS7UtZQdNRGC3cqVJefzwHtjzuSOfMovCnqsE/EBSW2TWhhvAkrL6Q18Ifm8BldH/giFk9IYfwZ5ja2eUa3HUSCdmVMI++ndnxdOcRak+soqnRwq8j8Svuh+tfhmnnqNduu6PtiCOd05UR4hR+zeTToM7htbfsV8J66s3wqZfjP5804g/Y7dC1fMa5hd8SU53OqUkX8ddMVbWDCorU3VXzPvXY8Jb9G2ZiE/UULbSZzsbNBoWl6hq72kzEP5AIIaqEEA8LIbYIId4UQqRZvqb3GI8/BySN+DMU/nQRf8sBexCyMVPhd4i8XsLPuS3caQ/gauEfPU9F3npg1J0K2d5gTeAqtnPpNTHhd0SzhaXx++k7gZqpifVh4jx+S5CiIeWLezx2LR+n1eM8r7OmDCjhTzU7VncIBX71PWjLq70+u1aPnp2cywlQusMOB3NrOeWQjIRfCFEqhBqVEULMFEJcIoToyz3Sz4B/SClnAwuAN/twrJSYmbsZ0LANHv+c/cfeV6KOPH7tT6daYtCN0+N3C3/THvv50W7WjI07htX765IMzoqSztLFWvh17vjM89Rj+dj4Y3Zo4U82uOvw+DW+ksQOAuJng2qcEbanwH6t7zrmXwlnfD5RNHXU6iuKt1AKy1ILW2zdV78SQP1dtB3pfuZuX4gVRcuh8Dt/DxPxp+UFoEgIMQ54GvgQcG9vTiiEqATOAO4GkFJ2SSmbenOsTDERfxoevBJe+43KFgHl8d5eqXLNe0PEkdXTJ6vHJfy6pIKvpAdWT9DOk9efd0b8zgXO9fn05KQpZ8ANa2Dxh+x9qiaqKpjhgD1z10kyqyfZWAAkTgqC+AjbU2ALr36ceCKc/eXEz8U8/hJlLWkyiviLrIjf6vjaj3Q/c7cv6DsoXe8nFzh/DyP8aRFSyg7gvcAdUsrLgbm9POcUoB74nRBinRDit0KIhJBICPEJIcRqIcTq+vr6Xp3I5PGn4MgWePbbKt3SnWWy+h71eHhj744d7S+rx+Xx64h/4kmZZwmFO+0SCrrUgVP4A42Jn3GuBlU7Pd4jr5lqjxX4iu16OVqY3RF/QZES82QRf7JJQE6hFV7bD+8u8tZRfUGRPQ4AlsffTcSvrZ7YIHdDdq0eXScopx6/U/jN4G46hOXDfwCwVjKgt/8rCoDFwJ1SykVAO3Cbeycp5V1SyqVSyqV1db37T6KTJKRR/nie/ZbKJ9/2lF2y112Xprd/ENrjD/cmqydNxN+0V2XBVE/uWVaPexGPcAqrB1R07BY7Z8RcNckW/sJSO+LXk6vcEb+2jZKVHk5m9Tizejxeuy3dCr8j4geYeYH9OlXEr8cCYhG/w+qJzdzNgvDr/wu5tHr8JuLPVPhvBr4IPCKl3CSEmAo828tz7gP2SSmtRTF5GNUR9DvG40+BFsOXf2kLbKw8gfVH39s/CGfEH+qh8Hd12FP53R5/x1EVJZbUKsHOZEwi3JlYSz6UJOLXtkuytV+d30Npnd0x1ky1I8eaKeoxlfAnK0+QNOJ3C7/V+XaXi+/0+AEuuxve/Ss1QN1txF8Y7/F3HLWvMRtWjyaXg7vOOzDdaQ8zMhJ+KeXzUspLpJTfswZ5G6SUN/XmhFLKQ8BeIcQsa9M5wObeHKs77IVYjPLHoa2XXS/a29yrTbmXscuUZB5/ZwbCf2A9vL3SFsSEdM5OJVKl1mpO7mjdjZTq/KV12P8TSO7xa3vElyQyjwmniBerutlKQJZcAwtWWPtaAu23rkFH+gWFSpxjQirsfZyksnq6y3mP+fVWx1VYCgtXqMldqWbIJnj8+vuU9sI12SxElsvVq5xWz6wLcteOHJJpVs8DQogKy4vfCGwWQnSzrlxabgTuF0JsABYC3+7DsVIiYkXa8oD/u0aVLOgPktVgdxck6011TYjP6tEiGw11X2P//65Wj3p2qjvfPtylbAstvs7iaEnbEVbpn77i+PTKOOE/pqLxWISeLOJ3pD1qe6KwXNV2F0LVcpnxDmufFBE/KDHWZReKKpLXLko1uOte7NyNFvHu7lh0251tLfCrTtXZkepJbtmwejS59Pj1/7E5lxiPvxuOk1K2AO8GnkQN0H4o7SfSIKVcb/n386WU75ZSppnH3nt0Hv+Q9/hDAdj0CKz8ev8cL9isFgCJO4eO+K2IPdpL4U+Wxw+Jdk9XR3zn0lavxODC76vX7o5CR/xafNMtrgJ2R+asmAmJg7slNQ7hTBLxa2Hw+u1MlJGz40tGF5araDu2OLmO+B2Wgl76T3hTV3eMS+f02sLfXcTvTSP8+tr0ProTiYv4g+q70DODB0L4uyuHnE2Kq+DTq+Dye3PXhhyTqfD7rLz9dwOPSSlDDIFA2pMvJRv2vtr9Pj0h2KwmKjmFJiHi76aGeyqcM3dDaYT/7nfCc9+xPhNRHc/Sa2H0fOvzLo8/3NmziF+PEbiFPxRQs1RBRbnF1Y7B0TTC6Yz462bH7+PxwEeegBM+rl4nu4OomQojj1PnS5bKCa6I3yn83Yhkuva7BV93IglZPcegznJftfBn0+Pv61oLfaVuVnY7tkFOpsL/a2AXUAq8IISYBGS40nLuiBVpi6bfb9Cz0/Li3TM2e0ugSYlY9WR7W0z4e1FPX0p442HVoaSM+F0pnUe324uKBJoAqXxfLbRv/l0VZdNEunoW8etzF/jjhXbzY/CzBap+T8fR+HN2Z/WUj1FjH2MWJO43brE9EzeZ1fOhR+C8b6toM1lGD8SPqzg9/m6tHp3Omazj0rVxyuOP5bwT6OqAzma7Xr22ArMhjCffAFOX9/9xDT0io9EbKeXPgZ87Nu0WQpyVav/BgidfPP5d/1aP/VXKNtisxGfENLv8gTudMxOrJxSAhz8K086CJz4HJ37SHihNJfy/uwhmX6gmQenceh29l4ywPem9r8Dz37f984jl8Wtx7Vb4U0T8R7epu5L2emVvVE+yI+t0g7sFfiirg4/+U90tpcNXpNrqtHq0iM6/Ekqqk38uIeK3Xnc7uJtBxB8T/sr4zxT47fRYne2l79SyMbh73v/0/zENPSajX9aabfs11IxbgOeBbwBJRgkHD3ZZ5iEu/Xohkd4OuDqJhFVJ2qJKGDEdtj2ttvfG6qnfAlsfV/9ARf7ussyazlb1/t5XbDHV2SM6u6akxiozXKg+H2yyPx+2VuTy+pRd0q3V44j4nRF2bIGYDsvqqUmcteskVkbYEsrxS9OfV1M9GSrGJW4/M01OhLtkg85G6tbjd6VzOolF/G6rx+Hx605eC7/+7rJp9RhySqZWzz1AK/B+618L8LtsNaq/sGfuDnHh19FybwdcneiZk0WVMPl02+6JRfw9sHrcnYOvKD6dM+SK+EMdKtrWJRd01B4T/tr4NgSaHOdyLJpRUtvDiL8q8f3OFnXnU1KTOAHKic6l7+m8ho8+DWfe2rPPOCN+4bUFOFOPP5nVE4v4LcGPRfzWvs45ArGIX1cENcKfr2Qq/NOklF+TUu6w/n0dGPTLzOfNQixa+Hs74OpER9FFVcpy+czrKoJ2R/yZdDLuAdtgs6tkQyB+36DV6ei6OV2t6rztDqsHiJlzgWN2vQ0d8YMa4HXW2UlGLOJ3WD1OD73lIAnjCskifv199HQZyOKqnn/GndWjf5NMPf50g9Mj56i7Gz0w7Ry01mjh1xVBcz0Aa8gamQp/QAgRq/4khDgVCKTZf1CQF1k9OuMF+ifi1wN37gqSbo8/k07GPWAbaIq3ozrb7Miyq82+23Cu8dre4Ij4XZN6oqH4iWWxiH+EPT6QCqfwl49WQuZc+ERn9hTXpPfInZZRtnF7/Pra+5LOqb+zkXPgCztV/SGI9/g1pSPszsfYPHlNpsL/SeCXQohdQohdwC+A67LWqn4itg7LENb9+OUIsyX8xY4CadaX5ZzItfYPyUskaOG/cS2MX2ZF/I4Oo7PFTr/sak8+caz9iPLaC8uSe9RPfxlWflNZN86IP2Orxw/zr4CPrYwvYKaFv6Q6fR7/pFNg5vlw4Q/Tn68/cGf16N+kO6tn0skw68Lk9W9i2TuOxVrA7iScCQPFNZkXhjMMaTLN6nkdWCCEqLBetwghbgY2ZLFtfSYvPH5nVO1eFKQ3aN/cOeDpK1YpfU5xb9wB91wAiz8Mj92g6tE4S/6CXVSt0Jr92nHUFfG3Khup5YCyVoJJMoB1xO9elESjq4WCHdmW1qmMnGgUXn9QLal45f3xn3NG/AV+lW7pjIhbMoz4fcVw1R+Tt62/cc/c1Z1+d1bPuCWw4sHk72nB14/jl6lObPLp6rW+dk+BVcbZqt1j/P28pkfdujV7V/NZ4Kf92pp+xq7Vk9Nm9A0t/AVF8aJ6eLOyTEYf37PjpbN6nHcXq+9Wj9pSaT2Uum2+EjVm0Lgj3o4KtijRmn0hrH/AniDkpL1eZehkUrulwDG4K62S0tufgS1/Vx2XswpmMovG+bzFmqRUXBW/WHkucRdp0/RlfdqYl19oH1dPNAO7QyiuVrfIsTUAjPDnM31ZenHQj/zkhcevB1CLquJF9akvwuP/ldkxGneoiUuQ3urp6kj87NFt6tFprYSC8PfP2ou36Ig/0BQ/NtDZqjqsMz6vJgi9/Ev7PS047fX2RKru8DqsHlAdRssB9fzAOvVvw5/glyfFl2zQOJ/rFFl/ZfrB3YEkrkib40+zT8KvV9rqpkpncU38fsbjz2v6IvyDXk3zYiEWHVUXV8WLarBF+ePJ2PAneOxG+/Wrd8HDH1FWTsNbqhNxVij0lSihdNbDL3T5ys5zHVyv7gi2PK4Gbz1e1T5nVg8oj7+gSM10LR9jdyKgMkh8pQ6rx+FP37IZrn0q8boKHIO7oDoNXR//3gvhruVw6A2of9OuNhkX8TuEX3eA/vL0Vs9A4rZ6NH2pa+O2etzo70dbbcbjHxak/XWFEK0kF3gB5PivpHt00DS0I37t81bFrzvrrKHu5i/WrfxFP1Z/yB0N9mzVPS/DxJPjU/V8xcrmiVv60JXH3+YQfqf94yxTICPxufedLfaAbcU4uwaMvh7hUcdtd0X8leOSL17ijvjbjtgRv0YLepvVRqfYuwePC4pUZ5JucHcgcadzavrSIdXNVjXnneU5nCRE/Fr4TcSfz6SN+KWU5VLKiiT/yqWUgz4kyI+I37J6iqviPf5QhxVhWwOy4c7EuveNO9WjTpc8+LqqkTPp5Pj9klk97iJpTqsn1glIuyyBniTlTrPUwlKpZ7EK+3rKRqqc/lB74uCuv5IEN7HAMbgLcGSzvTB4rJ3W+Vv2q6jVKZrukhfugmU5j/idHr/jz6sv+fR1M+HmDeq7TkYs4rfKSOgJa8bqyWv6YvUMevJiIRYdhWuPX19LKABIO8L93YXwHUtcdeTaYBVB08K/8S/qcaJb+PXgbpq1cZ1Wj7MT0JaRHjNwl1LQoqpL/upy0MVVSsDrt6jX7hWZPJ7EbBavy+o5mCSpTAt/8z7VJqdouoVfH1/X69H18nOJM4/+Q4/CO76Z3fNp4Xd7/Cbiz2vyWvjzokib0+MHO8LX5RC03bN/tXoMttjiqqtf6n22PqHskjEL488Ri/jTCH+bI5J3dgK6k9Htc+fXxyJ+S/hLa1U0X1ytnuvF3pMN7rpLLcRy0n1K1A+uV69HOTKb9N1I897EuvcJEb/lnY+cA/99SBWtyzWxdXY9qvjdqb1a6C5zEjx+k9UzHMhr4c+LIm3OrB6wB0916mXA5fMfXE+sq3v22/DUf9sRf2dL8nVYfSXK2nnlTmuDy1ooHakiaf09Ou2cmNVTGd+u2LFdVk9RJVz6CzjpU/GrMCUTfnf5YucAZUmtXVXyjM9D3Zz4tnUcTRR+t8fvzJYZLCsx6Yh/oAZXU2X1mMHdvCavhT8/PP52NQjqtyyVSEhl9+gOQEfz+g93/xrb65cRePkX8WI8Zn7iObS3vfs/cP53EyPfMfNV3R3dCTmj/5jVU2VvS5ZCqa0efwUcd4nqgEodvnMy4a9xtSOuvIBlDRUUw3GXwgXfU6+d15oq4o+1uQ9pktnC47B6BoKaqTD7YphiFd41Hv+wIK+F316IZRApfyQMf/ow7H45s/272pVQ6UjslTth1V32+zri1ylM+9dYAp1iQHB0EuHXttGpN8NJ19t//IVlcOYXYM671GsdTcdF/JbV454QptHrmzojfo3T109WbuDdd8BljiKwXofw6wllsy9SP7Sz9r0mwSqyhF8PdCZb8DzXDHTE7ytWs55rpqjXJqtnWJDXwj8oPf5ju2DzX+06+N3R1aZETQvB2vvsWbVgV7DUBdAOblBR7/Lb4CP/sPfTopdM+Bd9AJZ/Cc7+snqtfd6SGjjrS3a0riN9p8fvtnqc20DV/AcV3RcUxWfvxKwekXxVKl9x/J2A06I6/n3q8cIfJJ5T4474dSfkXPR8sKEze3IlvEb4hwV5LvzqcVB5/A1vqUdnTns6utqVqOk/yM62eKulo1Hl9Ou8e118rLBM3cZrRh2v7gpGzU08R+V4WP4Fx8LirsVHtCgHm1V55GCz3RFp28TjtT1zZ8Svhd/jgRUPqTsKjRb+4urUQuM8ljPiP+er8OV6uyPJRPjnXAIffca2kHK54HcqYlk9OfrTNDN3hwV5LfwiVrIhxw1xooVfzzjtDi382n7palXlDzSBRjuls2K8ndfuL1OWhs8SxLO/DFc+aI8VpEOfS3vqWtA7W2ybR4unU5i1teKcfOVMkZx2lp3dA7bwu1M5ncTl4TsifiHiXxcmua4Ej78QJiyz29eXUgjZwjPAVk/C+QviHw15SV4LPyh9GFTVOWPC35OIv8yOxp217EFF/Fr4Rzgi/MIydfE66h89H2adn9k59bl0xK8j484WO0+/doZ1HkekrYXWKcLpLIOSGhXZpqvTU5gi4neTbNatW/jd+w5Gqyfm8efK6jF5/MOBvBd+jxBD3OpxefxunBG/09rR0WzNFFJ66KmIWT6uhbo7W9U/sEsAOIVfnyPT0gcerxL9dMLvPFa6xVAK/In2RLIlF53HHIwRv7Z4chVxe01Wz3Ag7+/nPGIQpXNKqYRfeO2lCLuLOjtblXgnyzOvmghHdzgi/un2e9rSmXaWGgDuSQTntnoKS5UgBVvsVNHKCfZ7mljEryd1paix7+SET8S3243T6km37q0Q6k7DaYN1F/EPRo9fD+7mSnjN4O6wIO8jfiHE4PH4A8eUSI9ZoF53F/VLqYqQVYyzxdjJpNPUgiJ6hq4z713bLUuvhWv+3rN2uq0eIZRIdrbaufxjFkDlRBh5nP05HWEXV8M5X4OPPdP9uc68FY5/b+r3M434IbGwWyrhT5aCOljItdXjMcI/HMiZ8AshvEKIdUKIHqpSD8/DIPL4dXkCvXhKdwO8bUfUxKmqSXaKpRO9ItaOZ9Wjc+JVJoO4qfC6In5QOe+dLXZZh6qJcMsbMHahvY8WUo8PTv9s/5RA8Pos20N0b3/ouw89JyCVsFdPVncPzoHmwYJnsHj8eW8GDGtyGfF/Bngz2ycZVB5/sEk96ii5uwHept3qsXpS8oh/4knqD3T7SvW6aqIjzbIPNobHFfFDYsSfLH1Se/z9Xf7AV2J5+N1UqdRtKh8d3x43k0+DL+y29xtM5Hqxcx1gGI8/r8mJ8AshxgMXAb/N9rkGlceva9XXzVaPehWoVByzhL9qUnIxLa62CpRJNRDrnPDUH4t3ONMl/eXKptIRf7r0yf6OFn0l6f19jW6TXlQ93eBtsnr/g4Fcp3OarJ5hQa4i/p8CtwLRVDsIIT4hhFgthFhdX1+fardu8Qwmj19H/OVjVFStM2RS0bRLPVZNTB7x+0rscgq6fn5JrRKN7vzwdOiozxnxF1XYEX9BUXLrSXv8/R7xF2cm/Ho84ITr4D2/Hrzing7j8RsGgAEXfiHExcARKeWadPtJKe+SUi6VUi6tq6tLt2s35xtEM3e1x19cpTz4zlY4+nbqcsjHdqtSB4UlSYRWKHFf9tH4zaW1dg5/b3Fn9YBt9XS2Jbd5IN7j70+01dMdul11M2HBlf3bhoFisGT1GKsnr8lFxH8qcIkQYhfwEHC2EOJ/s3UyIcQgGtxtUo9FVbaQ/vpMePXXyfdv2q38fUgUU1+xEvfianjXz+Dcr6vt5WPsmjS9xV2yAZRtogd3Uwl/zOPvb6snw4hfWz2+FO0bCggvaiA7VyUbzJq7w4EB/3WllF8EvggghFgOfE5K+cFsnc8jBlGRtmCTElNfkRp8bTmgSjC4143VNO2FcYvVc7d94sxvX3KN/fysL9n193uLFm6vy+PXVk+qgeOsRfzFGUb8lrWTqmMaCni8ubVZjMc/LMj7PP5BldUTaLKjcX+Znc6pJ2Bt/DPccwFs+D9r/0Y7NdEdgaWaHVs9ye4sekvSrJ4KVQwucCxNxG9dWybReU8orc1sMlhxjarP35fxjVwjvLm1WWK1eozw5zM5vZ+TUj4HPJfNcwzYBK4D69WkpnTeerDJHgD1l6vP6O2hIPzlOrXASlGFmtQUbHaIqSuKdi8j2J/ErB6HgOoZxq0HVZZRMspGwfnfUwuj9CcXfF8tJt8dJ14H08/t2/hGrvF4c2uzmOqcw4K8j/gHpEjbGw/DXWeqOvvpCDTZPnhhmZ2JE2yGwxuV6HsK1ExcfReghT+Zx58tkmX16PTQloOpI34h4KRPQsWY/m1P2UiomtD9fiU1qvrmUEZ4cmz1mKye4UDeC/+A5PHveUU9ppqJG43AM19Xi6TEIn5HHnygSa2cBbBghVqsRfv+ySJ+X0nmhdB6Q9KsHiviDwcGZ42bfGHQCL8Z3M1nhoHwp/D433oanrm9f06iSxWnmjDU8Bb8+8eqgJiO+J37Bptg/1qVujntbEDC3lfVe7GI3/GHePx7YeY7+6ftyUhm9TjFfigPng52PLn2+E0653BgmAh/kjfe/Cu8dk//nERn0TgX+nZy9G37eWyxEkfEH2yGA2vVoOzIOWqbvotIFvGf/RU4/b/63OyUJLN6nAuqGOHPHsJk9RiyT94LP6SYwNXZprJU+oN2S/hTzcRtdAi/9u6dEXQ4CA3bVPmFmmnqj3+PtRh7Mo8/21krySL+Kke9oL7UATKkJ+eDuyarZziQ98Lv8aTw+Lva1eBqfwwAaG8/lfA7I369zGBC9UypqkYWFKoFVZr3qs0x4Xf8IWYzowdsgXeueOXx2AOsJuLPHrlO5zRZPcOCvB/B8aSauaurTIaDfcuQCRyza/C4hb+9AX55ohoDGH8CnP8duzJnsqhZ2ykjpsHRbeq5HhMQQglyNJR94U9WlhnU4iuNO4zwZxNPjgd3PWZwdziQ/xF/Ko/fKfw9ob0BHv+cGowFu4ImJAr/3lX2wO+IaTB+qWOh7zTCrxdUKaqMFwGvT0Xh2c5TrxyvBMBdtli3L5OcekPv8PhybPUYj384kPfCL0jj8YOaONUTtj8Dr/0GfnOWKqnQ7qgc6hb+Qxvs5+4/JG316D9y4VErbYG9gIm75o7Hl/1oH1Sd/9t22+WNNWMXqcehPEFqsHPyDfDOb+bu/MbjHxbk/f2cSJXHryti9jTi1xU2QQ3adrao5yW1icJ/cIOyR0ZMh2Ufj39PZ/VUjld5++Vj7fr3qYTfWzBw3msyO2fJR1S70y2VaOgb45fk9vzG4x8W5L3we4RAJivTFrN6emhb6AqbAG31ELI6kIoxdiegOfi6ip4vuzvxONrqqZqkhN+ZLqkXH08W8fd3HZye4PHAgityd35D9jFWz7Ag760ejxBE3cu9RCN2zn04kPihtnpYc2/yTkEP5IKyebRlVD7W7kxaDkLzfrUQul5Y3U1M+CfGP+pjFRQlifh9qrKnwZAtYkXa8j4mHNbkvfAnXYjFufBJMnFfey/87TNw70Wqk3ASOGavbdteb9s75aPV8y2Pw49nw69PVwOxsy5I3jBt9ZTWqaUYnTVmPB4481aY74qu+7qylsHQHcbqGRbkfbeetDqnU/hDSSJ+Leb7XlM5+iUjVBT/3HeU2BdXQySknvsrVGpmUaV6/ffPQtlo9fzCH0DtjOQN8xXDmV+A2RfDuV9LfD/ZzFzvAA3uGoYvRZWqvHX15Fy3xJBF8l74PQISlmLRlgyksHMcXv0LP4C1v1fi3tWqIqEpp4OMqtROUBk6uvZO2yH40CMw4aT0a74KoRZN6dHFGOE3ZJnCEvjCzly3wpBlhoHwJ4v4ncIfUHZOOGhnsjgHadf+3vqMdRcgI6rejvBC+xHlufvL4/Pyx5+QnYW+C0tMZUyDwdBn8t7j9yTz+DtdEf8rd8D/W2rnfQZboHIiKSmuVt689vj95XZefkFRknIM/cTFP7HX1jUYDIZekvfCT3cefzgIB9ZB6wH7TqCzBWomp147trhK1dxpb3AIvxWJ61m32WD0PKibmb3jGwyGYUHeC78n2QpcTqsnFLTLLmx/BlZ+U0X8RZV2yYJZF8K7fm4PeOmIP9QBrYdUho4eK6iZktXrMRgMhr4yDIRfJM7cjfP4g9BkCf/Lv4QXf6hWv/JXQrm1hODo+bDkaqgYr14XVSnhB/VZfwWMtRY4P/nT2boUg8Fg6BeGweBuNx5/oNGut3Noo/V+s7JudMSvyxHr2jXFVfElDfzlUDsdbm/u9/YbDAZDf5P3wi9IsvSi9viFF+rfsrc7Z/EWVRBLA9WzaiutImrF1fEzbU2mjcFgGELkt9XTtIfpoa1JrJ5WlX1TWAoNW5N/1l9hR/yVOuK3hL+oyt4G2cviMRgMhiyQ3xH/o5/iuuZ9fL72zvjtnW1qQFZ41MIioKJ/6SjPUFQBU89SE7X0oO7M82D/GqibpYpYldSqevsm4jcYDEOI/I74py5nUngnZZFj8dub96lqmnoWbEFxYjaOv0J5+6f/l11/vmoivOdXdr0cPfirZ+0aDAbDECDvhR9gbuf6+O3HdkL1FFvAK8dB6cj4fYoyEHNtBZnCaQaDYQiR38I/ZiHtopQTOl+28+yjEWjaoyJ8XeK4fIy9CHqBtf6uv7L74+sBXmeWkMFgMAxyBlz4hRAThBDPCiE2CyE2CSE+k7WTeQtYW3Iqp3e+APdfpra1HIBIlxXxW8JfMc7Oyx8zXz1mEvGf/WW1KtXcd/d70w0GgyFb5GJwNwz8l5RyrRCiHFgjhPinlHJzNk72+xGfIRru5Mz9a1UtnmNW5cGaKapePii/v3qy+jfyONj7ama+fUkNvOun2Wi2wWAwZI0Bj/illAellGut563Am8C4bJ0v4vGz1TtTpXB2NEKjJfzVU+wqnBXjYMk18JnXrUVWfKpkg8FgMOQhOU3nFEJMBhYBryZ57xPAJwAmTkxTKbMbPAIOCmsQ9tguFfF7CpTY64XTdXYOwLKPweTTzBKHBoMhb8nZ4K4Qogz4M3CzlLLF/b6U8i4p5VIp5dK6urpen6fI52VX1Pr8sZ1weLOqoOktUHcAYJdiAOXtTzih1+czGAyGwU5OhF8I4UOJ/v1Syr9k81y1ZX42dVSpF407YM8rMPEk9TpklW6oyJrTZDAYDIOOXGT1COBu4E0p5Y+zfb7askKOdBYgS0fC1idUAbZJp8TvVNr7OwqDwWAYauTC4z8V+BDwhhBivbXtS1LKJ7JxstoylbnTVTER/4HVaqMW/o8+A/tWgSe/pzMYDAaDkwEXfinlvwExUOfTwt9aPRf/wdVQM9WeeDVhmfpnMBgMw4j8LtIGjCgrBOD1ubdxztk3mro6BoNh2JP3wq8j/oaOMNTOyHFrDAaDIffkvbldV24Jf1tXjltiMBgMg4O8F/4in5cyfwENbZ25borBYDAMCvJe+EGldJqI32AwGBTDRPj9NLSaiN9gMBhgmAj/qIoi9jV15LoZBoPBMCgYFsK/ZFI1exsD7G8K5LopBoPBkHOGhfCfOl2trvWf7Q05bonBYDDknmEh/DNHlVFb5jfCbzAYDAwT4RdCcMq0Ebz09lGklLlujsFgMOSUYSH8AKdNr6W+tZNtR8zC6AaDYXgzbIT/lOkjAOPzGwwGw7AR/vHVJUwaUWKE32AwDHuGjfADnDN7FM9treerf93IZx5aZ/x+g8EwLBlWwv+ps6ZRXOjl9y/v5q/rD7BqZ2Oum2QwGAwDzrAS/toyPz9+/0KuXz6NqhIfv3h2OwebAwRDkVw3zWAwGAaMvK/H7+Ydx43iHceNoqLIx/f+sYWTv/Mv6sr9fPXi4zjYHODjp09FLQtsMBgM+cmwE37N9cuncer0Eaza2ciPnn6LGx9cB8CJU0awYEJVbhtnMBgMWWRYWT1u5o+v4mOnT+XH71/ARfPHUOzzctcLO3htVyOdYdv+kVLS3BHKYUsNBoOh/xBDIbNl6dKlcvXq1Vk/z21/3sBDr+0FQAgo8XmpLfdT5i9gy6FWbr9kLh88cSKRqGTD/mYWjK/C6zG2kMFgGJwIIdZIKZcmbDfCb9PU0cVLbx/FIwSbD7bQFgyzp7GdvY0BKot9rNrVyOkzaikp9PLUpsPMHl3OHz56InXlfrYfaWXLoVZmjipn5qhyAl0RIlJS5k/upjUHQlQUFaQcT/jXlsNMrCll+siybF6ywWDIY1IJ/7D1+JNRVVLIhfPGAHD+8aPj3otEJb9/eRc/X7mNYx0h3r90PH9Zu58fPb2Vc+eM4mO/tzumy5aM52+vH6AzHGXZ5Gp2H+3gxnNmsGl/M5cvnYBHwJV3vcI1p0zmixfOiX1ub2MHdeV+vvvkFu59aRejK4p44jOnU1NamNDWB1ftIRyJ8qGTJ3d7XapURSunTKvt5TczuDnYHGBnfTunWFVYmztCbD7YwsnTRmT0eSkl6/Y2sWhCVVxHHI5EKfAOazfUkEPCkShRCYUF/f9/0ET8PSQYivB2fRtzx1byzb9v5p7/7GREqZ+qEh8/vWIhP/nnW6zccoTZo8s5Z85IHt9wkFBExtYCqCgqwOsRNAVCeITgqhMmsnRyNU9tOsQTbxxiWl0pb9e3c/H8MTy96TALJlSyfNZIpJQ8vfkwUsJVJ07kK49uJColVyybSHlRAV84fzZ/WbuPrYda+eKFc2ho6+RAU4CFE6q44q5XWLWzkdsumM3BpgDBUJSz54wkEpVccPxouiJR9h8L8O/tDZw9eyTjq0tYtbORB1ft4YplEzhp6giaAyHueG47ly4Yx3FjKzjQFKC2zE9hgYcd9W2s39vEydNGMKayOOn3JqXklR2NzBxVhkcIdjd2MHNUGSWFduyxcX8zJYVeinxeCjyCkRVFGf0mn75/LU9vPsSar7yDiiIfH7vvNVZuOcKLt57F+OqSbj//j40H+eT/ruVXH1zCeXNH8cqORooLvVx9zyq+/Z55XDR/TMJnolGJxyNijwNFNs8XjUrufP5t3rt4XMrf0TBwPLvlCDc9uI6HrjuJuWMre3UMY/VkgdZgiFsf3sA/Nh3id9csY/mskbQEQ/z2hR2sOHFi7I/ncEuQmx5cx3lzR/PQa3sYX13Cp5ZP46YH19HQ3kVXOIq/wMN5c0fz2OsHmDSihKdvOYNnNh/hpofWEYmq36i6xEdZUQF7GwOU+QvwF3g42q7WEj5zZh0v7zhKVzjKhfNGs3rXMY60dnLmzDqef6ue8qICWoNhSgu9ALR3qcHrk6bW8Ko1kU1KKPAI3nHcKP6x6VBs268/tIRVOxu5+9878Qg4YUoNr+xopLyogHPnjOLR9fuRVmTymXNmsHBCFcePraSyxEdLMMSND6xjR0MbexsDLJlUzc6Gdhrbu7jg+NFcdeJECr0eRlYUceHPXqSwwIOUkvIiH/+4+XTKi3ys2d1IfWsXHV1hWoNhFk6oYtfRdhaMr2L7kTZueHAtwVCUX1y1CK8QXH//WgDOnTOSiiIf1505jZ8+8xbHOro4ZVot6/Yc4ysXH8fUOmWj3fTgOh57/QCnz6hlxQkT+dT9ayn2eQmEIowoLWThhCqKfF5CkSgfPW0K00eWcc6Pn+e6M6Zx/6u7uXj+WG67YDZSSh5es4/n3qpnZLmfK5dNZOaoMn757Hamjyzj/OPH0BmOcPtjmyj2FfCx06fwxBsHGVlRxCULxsb93+oMRwiGolQW+2Lbvv+PLfxtwwHuvnoZ7Z1hVu1s5A+v7OZHly/gxKnd3900tHXyo6ff4s2DLfzo/QuYVmfbiNGoZN3eY7zvzpdZccIEvvPe+XR0hXn3L//DJ86YxmVLxgNwqDnIiLJCfF4Pa/ccY0xlUcpO4tmtR3huyxHOnjOKvY0dNLR1Mnt0OQ1tXXzwpEkJ+x9qDrKzoZ2FE6rY2dDOnDHlCVZofWsnT248yFUnTEx7N9YVjlJY4OFwS5Bv/H0zn33HzLjrddPeGabAK7ji169w4pQadh1tZ92eJj555jSuPW0Kkaiksb2L6hL1e6SLxF9++ygNbZ28y/pNO8MRXnirgV0N7SyZXM3kEaVs3N/M6TNqEUIgpaS9K0KZv4BIVLL9SBuzRpfzpUfe4K/r9rP2q+/AX+BN2fZ0GOHPIi3BEBVFvu53dCGlJBKVPLHxEHPHVjCtroy/rN3HcWMrmD26AoA1uxsp8nmpKimkzF9ASaGXR9btZ1RFESNKC2kNhnnzYAvfefJNigq8vGfxOB56bS8jSgs5dXotz245woIJVXzr3cezYV8Ty2eNJNAVYcuhVn7x7Db+s/0olywYy+TaUt553Ch+tnIb/9x8mBUnTOC/3jmLq+9Zxd7GDgKhCBccP4bKYh8PrNrDlcsmcLglyDNvHuG8uaO4fvl0fvXc27EOo9jnZfaYcto7w+yob+es2SPxeQVPvHEIn1dw4bwx/HX9ATxC/REVeASl/gIKPAKPR3C0rRN/gZcZo8p463ArwVA09r2VFHrp6IpQWOChK6y2ewSU+gsIRaLMHFVOgUewdk8TAKWFXoQQVBb72N8UoMAjKCn0csq0WvY3BXhjf3NM6GeOKuPt+nYiUcm7F47lH5sOMbZKCVtLIERLMMwp00bw3Nb6uN/yhrOms78pwCPr9jO2soiG9i7CkSjHja1g4/4WCgs8zB5dzvYjbXR0JU4YfM+icbxd30ZJoZf/vvA4frZyG//eXs+p02qpLi3k1OkjuOWPryd8rsjnIRyRfPCkSYQiUS6aN4Y7n3+bySNK8XoEiydVc9LUGo60dHLDA2s52BxECFgwvoqKYh+3nDuTts4wn/jDaqbWlrJ2TxPFPi+vfOkcntp0iFsf3sCI0kK+9e7jqS4t5JrfreKcOaN43+JxfOy+1YypLGZcVTHHja0gHI2y9VAroyuLmTu2gh8//RZRKfEIQcT6v675/HmzmDeukgde3cO/th5hel0Zxzq6ONgcZPrIMrYfaWP26HJ+duUiZo0uj33uo/equ7nPvmMmCydU8cqOo6zf20Q4KvnqxccxoaaEbz/+Jn9eu49ffXAJf3hlN8+/Vc95c0cxd2wlF80fw6SaEoLhKJ+6fy3nzx3NqAo/n35gLZNHlLLlUCsAPq9gbFUxwVCEz583m+//YwtHWjsZZ21rDYY5//jRzBtXSVckyqHmII3tXZw0bQTffeJNAqEIf7/xdEZW+Ln23tfYsK8ZUP/P54yp4I39zcwYWcap02upK/fz85XbeODjJ/H0pkP8+oUdfOH82dz70k4WT6zmzg8u6ZmwODDCn+fsaminyxK9UCSKR4huM45agiHW7WniDCvyANUZHWoJxqK47Uda+dpjm6gs9vH1S46nrtxPZzgSi0B21LcxeUQpHo+KXF7bdYz2rjD/evMIOxraONrWxSfOmMp7F4+nKxzlI/eu4uzZo7h86XiW/+A5Rpb7uerEiexvCnDRvDGMqSzG5xX8Y+Mh1uw+xrNb6ynyefjAiUrY/rHxEHsbO3jn3NHsbGijrtzProYOZo4u52+vH2DGyDIe+PhJvLG/iV/8azsFXg+rdjby/cvmc8mCsexp7KDQ6+G7T25hw74mWjvVXcT3L5vPz57Zxv6mAJ85ZwYnTq3hhMk1ALHIsrG9i4/8bhWv72tmQk0xexsDnDmzjhGlhfxl3X68HsFNZ8/gpnOmW9bY27y4rYFTpo3g8Q0HiUrJO44bxekzamlsD3GkNciF88bwo6e38tLbR5k9upxdRzs41t5FOCqZPbqcjq4I+5sCRKKSeeMqufqUyTy+4QCnz6hj37EAnzprGp/7v9fjOqJyK6EgHJUEHLPSa8v8/PpDS3j+rXp+vnIbAKMq/ARDUZoDodg+DW2dXDhvNLuPdnC4pZOGts6E/zsFHsHUulL2NgYQAjq6IggByybVsPdYBwebg9SV+3nw4ydy5V2vEJVwzuyRHOsI0dYZ4pUd6i7T5xW8f+kEXt5xlGPtXYyqKGLLoVauO2Mqf1m3n2PtXZw2o5Y5Yyo42tbJn1bvi7VRt2Pu2AoOtQRpCYQp9RfQ1NFFVUkhzYEuQhHJ1LpSdtS3AyogCUWizB5Tzsb9LbHrKS300t4VYcbIMi5dOJbFE6tpCYb55P+uAWDRxCoumjeGf24+TEmhl0kjSvnfV3YTtjozn1dQXVLIkdZOyotUADOizE84EuVQS5DvvW8+iydWc+HPXqS1M8xF88bQ0NbJqzsbEULdWVcW++joClNe5KPRupP/0eULeJ91t9UbBpXwCyHOB34GeIHfSim/m25/I/z5yeGWIOVFBXE+vxt3dlRbZ5i2YJjRlbb/H41KjrR2smb3Md45dxQ+hwVwuCXIv7Yc4YqlE5J644GuCKt3N3La9FoONge57+VdXH/mNKpKEgfU9fl/8a/tvH/peJ7bWs85c0YysaaEf24+zNS6spRZWM0dIQoLPBQXpr9lb+ro4oYH1tEU6OIv159KYYGHZ7ceYc2uY3z6rOlJPy+lpDkQ4q/rD/D//rWd+65dxtyxlYQjUd7Y38zaPU1IKblsyXiqSgpp6wxzx7PbmTOmgtsf28RxYytYML6KXzy7nU+fNY2KIh/feXILAN+/bD6jK4qIRCV/eGU3F88fw+9f3s3EmhK+celcWoNhKop8PLXpECMr/LHxqNW7j1FTWsi0ujL2HO0gHI3GrLVwJMqOhnaaAyFGlRcxcUQJkaikKxylKxxl51Fl9xxpDfLbF3ey8s3D7DraQYFH8N7F47n53Bk8vGYf88ZVsmRSNaX+Ag41B/nZyrc41BzkhrOnE4pIrr5nFdcvVzbVB377Ku9fOoFth1s50Bxk1c5Gzp49knPnjMLrgXPmjOJbf9/MexeP54yZdQCEIlHO/tFzjK8q4d5rlyXYLW8ebCEqJVUlhRR4BHVlfjbsb6a00MuB5iC3Pvw6neEo91yzjMUTqwH485p9PPHGQe784BJ8XsGH71nFi9sa+MkVC/jb6wfZ2dDOgx8/iUfX72flm4f57YeXUVnSczdBM2iEXwjhBd4C3gHsA14DVkgpN6f6jBF+w3Cjt4O4UspelRzpDEf40dNv8eGTJzG+uoS369vwF3gyGhwfCLQt2pMsK+edqZNQJMp9L+3iovljuh3Ebu8MU+zz9uq36AxH6AxH09rAx9q72LC/mTOtzqa/GUzCfzJwu5TyPOv1FwGklN9J9Rkj/AaDwdBzUgl/LpKUxwF7Ha/3WdviEEJ8QgixWgixur6+3v22wWAwGHrJoJ2dIqW8S0q5VEq5tK4uO7dBBoPBMBzJhfDvByY4Xo+3thkMBoNhAMiF8L8GzBBCTBFCFAJXAo/loB0Gg8EwLBnwWj1SyrAQ4gbgKVQ65z1Syk0D3Q6DwWAYruSkSJuU8gngiVyc22AwGIY7g3Zw12AwGAzZwQi/wWAwDDOGRK0eIUQ9sLuXH68FGvqxObnEXMvgxFzL4CRfrqUv1zFJSpmQDz8khL8vCCFWJ5u5NhQx1zI4MdcyOMmXa8nGdRirx2AwGIYZRvgNBoNhmDEchP+uXDegHzHXMjgx1zI4yZdr6ffryHuP32AwGAzxDIeI32AwGAwOjPAbDAbDMCOvhV8Icb4QYqsQYrsQ4rZct6cnCCF2CSHeEEKsF0KstrbVCCH+KYTYZj1W57qdqRBC3COEOCKE2OjYlrT9QvFz63faIIRYnLuWx5PiOm4XQuy3fpv1QogLHe990bqOrUKI83LT6uQIISYIIZ4VQmwWQmwSQnzG2j4Uf5dU1zLkfhshRJEQYpUQ4nXrWr5ubZ8ihHjVavMfraKWCCH81uvt1vuTe3xSKWVe/kMVgHsbmAoUAq8Dx+W6XT1o/y6g1rXt+8Bt1vPbgO/lup1p2n8GsBjY2F37gQuBJwEBnAS8muv2d3MdtwOfS7Lvcdb/Mz8wxfr/5831NTjaNwZYbD0vRy2BetwQ/V1SXcuQ+22s77fMeu4DXrW+7z8BV1rbfwVcbz3/FPAr6/mVwB97es58jvhPALZLKXdIKbuAh4BLc9ymvnIpcJ/1/D7g3blrSnqklC8Aja7Nqdp/KfB7qXgFqBJCjBmQhnZDiutIxaXAQ1LKTinlTmA76v/hoEBKeVBKudZ63gq8iVr9bij+LqmuJRWD9rexvt8266XP+ieBs4GHre3u30X/Xg8D54geLrScz8Kf0RKPgxgJPC2EWCOE+IS1bZSU8qD1/BAwKjdN6zWp2j8Uf6sbLPvjHoflNmSuw7IHFqGiyyH9u7iuBYbgbyOE8Aoh1gNHgH+i7kiapJRhaxdne2PXYr3fDIzoyfnyWfiHOqdJKRcDFwCfFkKc4XxTqvu8IZuLO8TbfycwDVgIHAR+lNPW9BAhRBnwZ+BmKWWL872h9rskuZYh+dtIKSNSyoWoFQlPAGZn83z5LPxDeolHKeV+6/EI8AjqP8NhfattPR7JXQt7Rar2D6nfSkp52PpDjQK/wbYMBv11CCF8KKG8X0r5F2vzkPxdkl3LUP5tAKSUTcCzwMkoa02vmeJsb+xarPcrgaM9OU8+C/+QXeJRCFEqhCjXz4F3AhtR7b/a2u1q4K+5aWGvSdX+x4APW1kkJwHNDuth0OHyud+D+m1AXceVVtbFFGAGsGqg25cKywe+G3hTSvljx1tD7ndJdS1D8bcRQtQJIaqs58XAO1BjFs8Cl1m7uX8X/XtdBvzLulPLnFyPaGfzHyor4S2UX/bfuW5PD9o9FZWB8DqwSbcd5eOtBLYBzwA1uW5rmmt4EHWrHUL5kx9N1X5UVsMvrd/pDWBprtvfzXX8wWrnBuuPcIxj//+2rmMrcEGu2++6ltNQNs4GYL3178Ih+rukupYh99sA84F1Vps3Al+1tk9FdU7bgf8D/Nb2Iuv1duv9qT09pynZYDAYDMOMfLZ6DAaDwZAEI/wGg8EwzDDCbzAYDMMMI/wGg8EwzDDCbzAYDMMMI/wGAyCEiDgqOq4X/VjNVQgx2Vnd02DINQXd72IwDAsCUk2ZNxjyHhPxGwxpEGpdhO8LtTbCKiHEdGv7ZCHEv6xiYCuFEBOt7aOEEI9YtdVfF0KcYh3KK4T4jVVv/WlrhqbBkBOM8BsMimKX1XOF471mKeU84BfAT61t/w+4T0o5H7gf+Lm1/efA81LKBag6/pus7TOAX0op5wJNwPuyejUGQxrMzF2DARBCtEkpy5Js3wWcLaXcYRUFOySlHCGEaECVAwhZ2w9KKWuFEPXAeCllp+MYk4F/SilnWK+/APiklN8agEszGBIwEb/B0D0yxfOe0Ol4HsGMrxlyiBF+g6F7rnA8vmw9fwlV8RXgA8CL1vOVwPUQW1yjcqAaaTBkiok6DAZFsbUCkuYfUkqd0lkthNiAitpXWNtuBH4nhPg8UA98xNr+GeAuIcRHUZH99ajqngbDoMF4/AZDGiyPf6mUsiHXbTEY+gtj9RgMBsMww0T8BoPBMMwwEb/BYDAMM4zwGwwGwzDDCL/BYDAMM4zwGwwGwzDDCL/BYDAMM/4/4nlSzsOx1+UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_acc(h, title=\"accuracy\"):\n",
    "    plt.plot(h.history['accuracy'])\n",
    "    plt.plot(h.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    # plt.legend(['Training'], loc=0)\n",
    "\n",
    "\n",
    "def plot_loss(h, title=\"loss\"):\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    # plt.legend(['Training'], loc=0)\n",
    "\n",
    "\n",
    "plot_loss(history3)\n",
    "plt.show()\n",
    "# plt.savefig('loss_graph.png')\n",
    "# plt.clf()\n",
    "plot_acc(history3)\n",
    "# plt.savefig('acc_graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model.evaluate_generator(\n",
    "#             test_generator, \n",
    "#             steps = 5)\n",
    "\n",
    "# print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "#  \n",
    "# print(\"-- Predict --\")\n",
    "\n",
    "# output = model.predict_generator(\n",
    "#             test_generator, \n",
    "#             steps = 5)\n",
    "\n",
    "# np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]]\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# test = cv2.imread('./data/Img/char/train/upper/B/img012-005.png')\n",
    "test = cv2.imread('./data/Img/char/test/c.png')\n",
    "test = pre_processing(test)\n",
    "test = test.reshape(1, 84, 84, 1)\n",
    "pred = model2.predict(test)\n",
    "print(train_generator.class_indices)\n",
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "print(np.argmax(pred[[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "65/65 [==============================] - 22s 197ms/step - loss: 10.2402 - accuracy: 0.2915 - val_loss: 2.3677 - val_accuracy: 0.5083\n",
      "Epoch 2/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 1.9413 - accuracy: 0.4885 - val_loss: 2.1507 - val_accuracy: 0.5750\n",
      "Epoch 3/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 1.3017 - accuracy: 0.6415 - val_loss: 2.1335 - val_accuracy: 0.6500\n",
      "Epoch 4/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 1.0725 - accuracy: 0.7185 - val_loss: 1.7034 - val_accuracy: 0.7500\n",
      "Epoch 5/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.8666 - accuracy: 0.7538 - val_loss: 1.6958 - val_accuracy: 0.7250\n",
      "Epoch 6/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.7695 - accuracy: 0.7923 - val_loss: 1.9332 - val_accuracy: 0.7417\n",
      "Epoch 7/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.8322 - accuracy: 0.7808 - val_loss: 2.3538 - val_accuracy: 0.7417\n",
      "Epoch 8/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.6994 - accuracy: 0.8115 - val_loss: 3.5224 - val_accuracy: 0.6417\n",
      "Epoch 9/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.6728 - accuracy: 0.8254 - val_loss: 1.7825 - val_accuracy: 0.7917\n",
      "Epoch 10/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.6764 - accuracy: 0.8277 - val_loss: 2.3133 - val_accuracy: 0.7333\n",
      "Epoch 11/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.5963 - accuracy: 0.8446 - val_loss: 2.7564 - val_accuracy: 0.7417\n",
      "Epoch 12/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.6498 - accuracy: 0.8454 - val_loss: 2.0976 - val_accuracy: 0.7750\n",
      "Epoch 13/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.5077 - accuracy: 0.8623 - val_loss: 2.6193 - val_accuracy: 0.7333\n",
      "Epoch 14/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.5177 - accuracy: 0.8677 - val_loss: 2.0237 - val_accuracy: 0.7750\n",
      "Epoch 15/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.5015 - accuracy: 0.8700 - val_loss: 3.0025 - val_accuracy: 0.7000\n",
      "Epoch 16/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.4960 - accuracy: 0.8769 - val_loss: 2.9590 - val_accuracy: 0.7750\n",
      "Epoch 17/300\n",
      "65/65 [==============================] - 11s 155ms/step - loss: 0.4958 - accuracy: 0.8777 - val_loss: 2.4031 - val_accuracy: 0.7667\n",
      "Epoch 18/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.4778 - accuracy: 0.8838 - val_loss: 2.8677 - val_accuracy: 0.7500\n",
      "Epoch 19/300\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.5092 - accuracy: 0.8885 - val_loss: 2.6904 - val_accuracy: 0.7833\n",
      "Epoch 20/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.4599 - accuracy: 0.8838 - val_loss: 2.9036 - val_accuracy: 0.7917\n",
      "Epoch 21/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.4254 - accuracy: 0.8969 - val_loss: 2.3958 - val_accuracy: 0.8000\n",
      "Epoch 22/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.4018 - accuracy: 0.9000 - val_loss: 3.2352 - val_accuracy: 0.7833\n",
      "Epoch 23/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.4620 - accuracy: 0.8869 - val_loss: 3.2037 - val_accuracy: 0.7917\n",
      "Epoch 24/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.4313 - accuracy: 0.8985 - val_loss: 2.5446 - val_accuracy: 0.8167\n",
      "Epoch 25/300\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.3308 - accuracy: 0.9154 - val_loss: 2.1741 - val_accuracy: 0.7917\n",
      "Epoch 26/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2964 - accuracy: 0.9138 - val_loss: 3.2376 - val_accuracy: 0.7917\n",
      "Epoch 27/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.3988 - accuracy: 0.9077 - val_loss: 3.6638 - val_accuracy: 0.8083\n",
      "Epoch 28/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.4100 - accuracy: 0.9085 - val_loss: 2.6053 - val_accuracy: 0.8417\n",
      "Epoch 29/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3976 - accuracy: 0.9054 - val_loss: 2.8961 - val_accuracy: 0.8000\n",
      "Epoch 30/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.3256 - accuracy: 0.9185 - val_loss: 2.9838 - val_accuracy: 0.8583\n",
      "Epoch 31/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.3936 - accuracy: 0.9023 - val_loss: 2.9371 - val_accuracy: 0.8167\n",
      "Epoch 32/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.3923 - accuracy: 0.9223 - val_loss: 3.0155 - val_accuracy: 0.8500\n",
      "Epoch 33/300\n",
      "65/65 [==============================] - 11s 160ms/step - loss: 0.3639 - accuracy: 0.9185 - val_loss: 3.3111 - val_accuracy: 0.8000\n",
      "Epoch 34/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3874 - accuracy: 0.9169 - val_loss: 3.1768 - val_accuracy: 0.8000\n",
      "Epoch 35/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3115 - accuracy: 0.9346 - val_loss: 3.5711 - val_accuracy: 0.8417\n",
      "Epoch 36/300\n",
      "65/65 [==============================] - 10s 154ms/step - loss: 0.3737 - accuracy: 0.9185 - val_loss: 3.3732 - val_accuracy: 0.8167\n",
      "Epoch 37/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.3083 - accuracy: 0.9208 - val_loss: 4.2287 - val_accuracy: 0.7667\n",
      "Epoch 38/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.3276 - accuracy: 0.9277 - val_loss: 4.5920 - val_accuracy: 0.7917\n",
      "Epoch 39/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.3991 - accuracy: 0.9177 - val_loss: 4.0541 - val_accuracy: 0.8333\n",
      "Epoch 40/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.3038 - accuracy: 0.9215 - val_loss: 2.9602 - val_accuracy: 0.8500\n",
      "Epoch 41/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.3107 - accuracy: 0.9285 - val_loss: 3.8878 - val_accuracy: 0.8083\n",
      "Epoch 42/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2792 - accuracy: 0.9254 - val_loss: 2.9966 - val_accuracy: 0.8000\n",
      "Epoch 43/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.3184 - accuracy: 0.9285 - val_loss: 3.4551 - val_accuracy: 0.8000\n",
      "Epoch 44/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.3459 - accuracy: 0.9138 - val_loss: 3.7315 - val_accuracy: 0.8000\n",
      "Epoch 45/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2731 - accuracy: 0.9377 - val_loss: 3.7507 - val_accuracy: 0.8500\n",
      "Epoch 46/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.3708 - accuracy: 0.9231 - val_loss: 3.4044 - val_accuracy: 0.7917\n",
      "Epoch 47/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.4152 - accuracy: 0.9215 - val_loss: 3.0143 - val_accuracy: 0.8417\n",
      "Epoch 48/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3390 - accuracy: 0.9269 - val_loss: 3.8262 - val_accuracy: 0.8167\n",
      "Epoch 49/300\n",
      "65/65 [==============================] - 10s 155ms/step - loss: 0.2814 - accuracy: 0.9315 - val_loss: 4.2699 - val_accuracy: 0.7917\n",
      "Epoch 50/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.3129 - accuracy: 0.9369 - val_loss: 5.4953 - val_accuracy: 0.8250\n",
      "Epoch 51/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.2900 - accuracy: 0.9392 - val_loss: 5.7194 - val_accuracy: 0.7583\n",
      "Epoch 52/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.3325 - accuracy: 0.9423 - val_loss: 2.8065 - val_accuracy: 0.8583\n",
      "Epoch 53/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.2997 - accuracy: 0.9431 - val_loss: 4.5889 - val_accuracy: 0.7833\n",
      "Epoch 54/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.2729 - accuracy: 0.9369 - val_loss: 3.5681 - val_accuracy: 0.7917\n",
      "Epoch 55/300\n",
      "65/65 [==============================] - 10s 154ms/step - loss: 0.3747 - accuracy: 0.9346 - val_loss: 5.0758 - val_accuracy: 0.8250\n",
      "Epoch 56/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.2784 - accuracy: 0.9469 - val_loss: 4.3008 - val_accuracy: 0.8250\n",
      "Epoch 57/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.3201 - accuracy: 0.9477 - val_loss: 4.0337 - val_accuracy: 0.8083\n",
      "Epoch 58/300\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.2647 - accuracy: 0.9385 - val_loss: 3.9111 - val_accuracy: 0.8500\n",
      "Epoch 59/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2278 - accuracy: 0.9538 - val_loss: 4.8357 - val_accuracy: 0.7750\n",
      "Epoch 60/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.3207 - accuracy: 0.9362 - val_loss: 4.5637 - val_accuracy: 0.8000\n",
      "Epoch 61/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2543 - accuracy: 0.9523 - val_loss: 3.8743 - val_accuracy: 0.8083\n",
      "Epoch 62/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.2429 - accuracy: 0.9500 - val_loss: 4.9856 - val_accuracy: 0.8000\n",
      "Epoch 63/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.2973 - accuracy: 0.9485 - val_loss: 4.6297 - val_accuracy: 0.8417\n",
      "Epoch 64/300\n",
      "65/65 [==============================] - 10s 155ms/step - loss: 0.2526 - accuracy: 0.9492 - val_loss: 4.7003 - val_accuracy: 0.8000\n",
      "Epoch 65/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.2538 - accuracy: 0.9531 - val_loss: 4.2919 - val_accuracy: 0.8250\n",
      "Epoch 66/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.3573 - accuracy: 0.9423 - val_loss: 5.0242 - val_accuracy: 0.8167\n",
      "Epoch 67/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2813 - accuracy: 0.9423 - val_loss: 4.4887 - val_accuracy: 0.8167\n",
      "Epoch 68/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3053 - accuracy: 0.9469 - val_loss: 4.7907 - val_accuracy: 0.8000\n",
      "Epoch 69/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.3164 - accuracy: 0.9377 - val_loss: 5.0318 - val_accuracy: 0.8167\n",
      "Epoch 70/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2865 - accuracy: 0.9462 - val_loss: 5.9298 - val_accuracy: 0.7833\n",
      "Epoch 71/300\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.3014 - accuracy: 0.9485 - val_loss: 5.8037 - val_accuracy: 0.8333\n",
      "Epoch 72/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2258 - accuracy: 0.9577 - val_loss: 5.4134 - val_accuracy: 0.8333\n",
      "Epoch 73/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2815 - accuracy: 0.9585 - val_loss: 6.0464 - val_accuracy: 0.8250\n",
      "Epoch 74/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.2717 - accuracy: 0.9508 - val_loss: 4.5938 - val_accuracy: 0.8083\n",
      "Epoch 75/300\n",
      "65/65 [==============================] - 12s 186ms/step - loss: 0.3053 - accuracy: 0.9462 - val_loss: 4.6867 - val_accuracy: 0.8167\n",
      "Epoch 76/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2818 - accuracy: 0.9531 - val_loss: 4.7174 - val_accuracy: 0.8417\n",
      "Epoch 77/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.2377 - accuracy: 0.9562 - val_loss: 6.0073 - val_accuracy: 0.7917\n",
      "Epoch 78/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2787 - accuracy: 0.9508 - val_loss: 3.2726 - val_accuracy: 0.8250\n",
      "Epoch 79/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3165 - accuracy: 0.9438 - val_loss: 5.1535 - val_accuracy: 0.8083\n",
      "Epoch 80/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2858 - accuracy: 0.9562 - val_loss: 4.6500 - val_accuracy: 0.8500\n",
      "Epoch 81/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2027 - accuracy: 0.9615 - val_loss: 5.1907 - val_accuracy: 0.8417\n",
      "Epoch 82/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2084 - accuracy: 0.9585 - val_loss: 4.5441 - val_accuracy: 0.8333\n",
      "Epoch 83/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.3121 - accuracy: 0.9515 - val_loss: 3.5300 - val_accuracy: 0.8667\n",
      "Epoch 84/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2752 - accuracy: 0.9569 - val_loss: 3.1979 - val_accuracy: 0.8833\n",
      "Epoch 85/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2437 - accuracy: 0.9577 - val_loss: 4.3839 - val_accuracy: 0.8333\n",
      "Epoch 86/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2883 - accuracy: 0.9585 - val_loss: 5.0340 - val_accuracy: 0.8417\n",
      "Epoch 87/300\n",
      "65/65 [==============================] - 10s 155ms/step - loss: 0.2710 - accuracy: 0.9523 - val_loss: 4.2353 - val_accuracy: 0.8583\n",
      "Epoch 88/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2354 - accuracy: 0.9523 - val_loss: 5.4889 - val_accuracy: 0.8083\n",
      "Epoch 89/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2864 - accuracy: 0.9531 - val_loss: 5.2998 - val_accuracy: 0.8250\n",
      "Epoch 90/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.3007 - accuracy: 0.9492 - val_loss: 5.5270 - val_accuracy: 0.8000\n",
      "Epoch 91/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.2706 - accuracy: 0.9538 - val_loss: 4.6274 - val_accuracy: 0.8583\n",
      "Epoch 92/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2299 - accuracy: 0.9554 - val_loss: 3.7528 - val_accuracy: 0.8500\n",
      "Epoch 93/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2373 - accuracy: 0.9492 - val_loss: 6.6486 - val_accuracy: 0.7917\n",
      "Epoch 94/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2125 - accuracy: 0.9654 - val_loss: 4.2553 - val_accuracy: 0.8833\n",
      "Epoch 95/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2054 - accuracy: 0.9615 - val_loss: 4.6344 - val_accuracy: 0.8250\n",
      "Epoch 96/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.1995 - accuracy: 0.9600 - val_loss: 6.3495 - val_accuracy: 0.8417\n",
      "Epoch 97/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2698 - accuracy: 0.9562 - val_loss: 5.1660 - val_accuracy: 0.8083\n",
      "Epoch 98/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.2645 - accuracy: 0.9562 - val_loss: 5.0486 - val_accuracy: 0.7917\n",
      "Epoch 99/300\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.2979 - accuracy: 0.9523 - val_loss: 4.5461 - val_accuracy: 0.8583\n",
      "Epoch 100/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.1951 - accuracy: 0.9615 - val_loss: 5.5006 - val_accuracy: 0.8250\n",
      "Epoch 101/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.2881 - accuracy: 0.9569 - val_loss: 4.7657 - val_accuracy: 0.8417\n",
      "Epoch 102/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2887 - accuracy: 0.9554 - val_loss: 5.6206 - val_accuracy: 0.8250\n",
      "Epoch 103/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.1770 - accuracy: 0.9654 - val_loss: 4.9574 - val_accuracy: 0.8500\n",
      "Epoch 104/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2469 - accuracy: 0.9638 - val_loss: 4.3034 - val_accuracy: 0.8333\n",
      "Epoch 105/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2175 - accuracy: 0.9669 - val_loss: 5.0397 - val_accuracy: 0.8583\n",
      "Epoch 106/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2196 - accuracy: 0.9608 - val_loss: 5.7486 - val_accuracy: 0.8417\n",
      "Epoch 107/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.3000 - accuracy: 0.9531 - val_loss: 5.7257 - val_accuracy: 0.8583\n",
      "Epoch 108/300\n",
      "65/65 [==============================] - 11s 158ms/step - loss: 0.2338 - accuracy: 0.9600 - val_loss: 7.1059 - val_accuracy: 0.8083\n",
      "Epoch 109/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2944 - accuracy: 0.9600 - val_loss: 5.0598 - val_accuracy: 0.8583\n",
      "Epoch 110/300\n",
      "65/65 [==============================] - 11s 160ms/step - loss: 0.2103 - accuracy: 0.9615 - val_loss: 5.5343 - val_accuracy: 0.8500\n",
      "Epoch 111/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2198 - accuracy: 0.9600 - val_loss: 4.6747 - val_accuracy: 0.8583\n",
      "Epoch 112/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.1824 - accuracy: 0.9638 - val_loss: 5.2105 - val_accuracy: 0.8167\n",
      "Epoch 113/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2491 - accuracy: 0.9562 - val_loss: 3.7681 - val_accuracy: 0.8583\n",
      "Epoch 114/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2098 - accuracy: 0.9646 - val_loss: 5.8733 - val_accuracy: 0.8583\n",
      "Epoch 115/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.2580 - accuracy: 0.9662 - val_loss: 6.3394 - val_accuracy: 0.8250\n",
      "Epoch 116/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.1766 - accuracy: 0.9646 - val_loss: 5.9478 - val_accuracy: 0.8333\n",
      "Epoch 117/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2513 - accuracy: 0.9585 - val_loss: 5.2373 - val_accuracy: 0.8583\n",
      "Epoch 118/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.1955 - accuracy: 0.9685 - val_loss: 4.5669 - val_accuracy: 0.8083\n",
      "Epoch 119/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.2446 - accuracy: 0.9592 - val_loss: 4.6477 - val_accuracy: 0.8583\n",
      "Epoch 120/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.1885 - accuracy: 0.9723 - val_loss: 5.1589 - val_accuracy: 0.8583\n",
      "Epoch 121/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.3577 - accuracy: 0.9469 - val_loss: 4.7553 - val_accuracy: 0.8500\n",
      "Epoch 122/300\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.1664 - accuracy: 0.9731 - val_loss: 5.0153 - val_accuracy: 0.8750\n",
      "Epoch 123/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.1967 - accuracy: 0.9708 - val_loss: 3.7636 - val_accuracy: 0.8583\n",
      "Epoch 124/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2600 - accuracy: 0.9638 - val_loss: 5.0522 - val_accuracy: 0.7833\n",
      "Epoch 125/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.3548 - accuracy: 0.9562 - val_loss: 4.0359 - val_accuracy: 0.8250\n",
      "Epoch 126/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.1963 - accuracy: 0.9685 - val_loss: 4.9446 - val_accuracy: 0.8833\n",
      "Epoch 127/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.2650 - accuracy: 0.9669 - val_loss: 6.7564 - val_accuracy: 0.8333\n",
      "Epoch 128/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.1612 - accuracy: 0.9731 - val_loss: 6.1732 - val_accuracy: 0.8667\n",
      "Epoch 129/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2562 - accuracy: 0.9608 - val_loss: 5.2831 - val_accuracy: 0.8583\n",
      "Epoch 130/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2671 - accuracy: 0.9569 - val_loss: 6.2770 - val_accuracy: 0.8250\n",
      "Epoch 131/300\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.2323 - accuracy: 0.9677 - val_loss: 4.5525 - val_accuracy: 0.8417\n",
      "Epoch 132/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2651 - accuracy: 0.9615 - val_loss: 5.5687 - val_accuracy: 0.8083\n",
      "Epoch 133/300\n",
      "65/65 [==============================] - 10s 153ms/step - loss: 0.2143 - accuracy: 0.9631 - val_loss: 4.1716 - val_accuracy: 0.9000\n",
      "Epoch 134/300\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1955 - accuracy: 0.9615 - val_loss: 5.1600 - val_accuracy: 0.8500\n",
      "Epoch 135/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2130 - accuracy: 0.9723 - val_loss: 5.9268 - val_accuracy: 0.8833\n",
      "Epoch 136/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.1705 - accuracy: 0.9708 - val_loss: 6.6834 - val_accuracy: 0.8500\n",
      "Epoch 137/300\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.3510 - accuracy: 0.9631 - val_loss: 4.8467 - val_accuracy: 0.8333\n",
      "Epoch 138/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.2086 - accuracy: 0.9669 - val_loss: 6.3112 - val_accuracy: 0.8583\n",
      "Epoch 139/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.1554 - accuracy: 0.9746 - val_loss: 6.2444 - val_accuracy: 0.8833\n",
      "Epoch 140/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2985 - accuracy: 0.9692 - val_loss: 6.2723 - val_accuracy: 0.8583\n",
      "Epoch 141/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2267 - accuracy: 0.9669 - val_loss: 6.3456 - val_accuracy: 0.8667\n",
      "Epoch 142/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.3378 - accuracy: 0.9654 - val_loss: 6.0739 - val_accuracy: 0.8333\n",
      "Epoch 143/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.2449 - accuracy: 0.9677 - val_loss: 7.4597 - val_accuracy: 0.8083\n",
      "Epoch 144/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2623 - accuracy: 0.9654 - val_loss: 5.2571 - val_accuracy: 0.8583\n",
      "Epoch 145/300\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.2559 - accuracy: 0.9677 - val_loss: 6.2951 - val_accuracy: 0.8583\n",
      "Epoch 146/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2618 - accuracy: 0.9608 - val_loss: 6.2558 - val_accuracy: 0.8583\n",
      "Epoch 147/300\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.2099 - accuracy: 0.9646 - val_loss: 5.5638 - val_accuracy: 0.8583\n",
      "Epoch 148/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.1551 - accuracy: 0.9731 - val_loss: 5.9015 - val_accuracy: 0.8500\n",
      "Epoch 149/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2804 - accuracy: 0.9631 - val_loss: 7.4632 - val_accuracy: 0.8167\n",
      "Epoch 150/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.1600 - accuracy: 0.9738 - val_loss: 6.9593 - val_accuracy: 0.8083\n",
      "Epoch 151/300\n",
      "65/65 [==============================] - 10s 152ms/step - loss: 0.2798 - accuracy: 0.9569 - val_loss: 5.8196 - val_accuracy: 0.8583\n",
      "Epoch 152/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2130 - accuracy: 0.9654 - val_loss: 6.5652 - val_accuracy: 0.8167\n",
      "Epoch 153/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.1679 - accuracy: 0.9746 - val_loss: 5.6741 - val_accuracy: 0.8583\n",
      "Epoch 154/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.1994 - accuracy: 0.9677 - val_loss: 7.4903 - val_accuracy: 0.8333\n",
      "Epoch 155/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2483 - accuracy: 0.9692 - val_loss: 7.3098 - val_accuracy: 0.8000\n",
      "Epoch 156/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.2613 - accuracy: 0.9631 - val_loss: 6.4113 - val_accuracy: 0.8250\n",
      "Epoch 157/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2443 - accuracy: 0.9731 - val_loss: 5.4598 - val_accuracy: 0.8500\n",
      "Epoch 158/300\n",
      "65/65 [==============================] - 11s 172ms/step - loss: 0.2113 - accuracy: 0.9646 - val_loss: 6.8301 - val_accuracy: 0.8250\n",
      "Epoch 159/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.1978 - accuracy: 0.9708 - val_loss: 6.2889 - val_accuracy: 0.8500\n",
      "Epoch 160/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2596 - accuracy: 0.9715 - val_loss: 6.8721 - val_accuracy: 0.8333\n",
      "Epoch 161/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.1814 - accuracy: 0.9731 - val_loss: 5.6330 - val_accuracy: 0.8167\n",
      "Epoch 162/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2182 - accuracy: 0.9677 - val_loss: 6.3727 - val_accuracy: 0.8500\n",
      "Epoch 163/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2139 - accuracy: 0.9746 - val_loss: 5.5363 - val_accuracy: 0.8333\n",
      "Epoch 164/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.2678 - accuracy: 0.9692 - val_loss: 6.4154 - val_accuracy: 0.7917\n",
      "Epoch 165/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2124 - accuracy: 0.9662 - val_loss: 6.2428 - val_accuracy: 0.8667\n",
      "Epoch 166/300\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2364 - accuracy: 0.9646 - val_loss: 6.8150 - val_accuracy: 0.8167\n",
      "Epoch 167/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.2536 - accuracy: 0.9654 - val_loss: 7.8374 - val_accuracy: 0.8083\n",
      "Epoch 168/300\n",
      "65/65 [==============================] - 10s 161ms/step - loss: 0.1923 - accuracy: 0.9762 - val_loss: 6.6370 - val_accuracy: 0.8500\n",
      "Epoch 169/300\n",
      "65/65 [==============================] - 12s 184ms/step - loss: 0.2005 - accuracy: 0.9738 - val_loss: 7.2080 - val_accuracy: 0.8250\n",
      "Epoch 170/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2160 - accuracy: 0.9662 - val_loss: 8.2587 - val_accuracy: 0.8000\n",
      "Epoch 171/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.1821 - accuracy: 0.9669 - val_loss: 3.2479 - val_accuracy: 0.8917\n",
      "Epoch 172/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.1331 - accuracy: 0.9738 - val_loss: 7.5561 - val_accuracy: 0.8500\n",
      "Epoch 173/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2306 - accuracy: 0.9708 - val_loss: 8.1046 - val_accuracy: 0.8000\n",
      "Epoch 174/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.1952 - accuracy: 0.9731 - val_loss: 4.8685 - val_accuracy: 0.8583\n",
      "Epoch 175/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2100 - accuracy: 0.9677 - val_loss: 5.8739 - val_accuracy: 0.8500\n",
      "Epoch 176/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.1552 - accuracy: 0.9769 - val_loss: 9.2923 - val_accuracy: 0.8000\n",
      "Epoch 177/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.1986 - accuracy: 0.9700 - val_loss: 6.6217 - val_accuracy: 0.8333\n",
      "Epoch 178/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2794 - accuracy: 0.9685 - val_loss: 6.1044 - val_accuracy: 0.8417\n",
      "Epoch 179/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2018 - accuracy: 0.9715 - val_loss: 6.3832 - val_accuracy: 0.8583\n",
      "Epoch 180/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.2400 - accuracy: 0.9669 - val_loss: 7.5250 - val_accuracy: 0.8250\n",
      "Epoch 181/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2099 - accuracy: 0.9715 - val_loss: 6.9790 - val_accuracy: 0.8250\n",
      "Epoch 182/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.2761 - accuracy: 0.9692 - val_loss: 6.9832 - val_accuracy: 0.8167\n",
      "Epoch 183/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.2324 - accuracy: 0.9585 - val_loss: 7.2228 - val_accuracy: 0.8083\n",
      "Epoch 184/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.1825 - accuracy: 0.9738 - val_loss: 5.2542 - val_accuracy: 0.8583\n",
      "Epoch 185/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2032 - accuracy: 0.9692 - val_loss: 6.8126 - val_accuracy: 0.8167\n",
      "Epoch 186/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.1340 - accuracy: 0.9731 - val_loss: 7.6887 - val_accuracy: 0.8167\n",
      "Epoch 187/300\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.2081 - accuracy: 0.9623 - val_loss: 6.0744 - val_accuracy: 0.8583\n",
      "Epoch 188/300\n",
      "65/65 [==============================] - 11s 174ms/step - loss: 0.1946 - accuracy: 0.9669 - val_loss: 5.8927 - val_accuracy: 0.8667\n",
      "Epoch 189/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.1981 - accuracy: 0.9715 - val_loss: 6.9811 - val_accuracy: 0.8167\n",
      "Epoch 190/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.1816 - accuracy: 0.9654 - val_loss: 7.0376 - val_accuracy: 0.8417\n",
      "Epoch 191/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.1676 - accuracy: 0.9738 - val_loss: 4.9661 - val_accuracy: 0.8583\n",
      "Epoch 192/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.1646 - accuracy: 0.9762 - val_loss: 7.2194 - val_accuracy: 0.8583\n",
      "Epoch 193/300\n",
      "65/65 [==============================] - 11s 159ms/step - loss: 0.2014 - accuracy: 0.9754 - val_loss: 5.3564 - val_accuracy: 0.8583\n",
      "Epoch 194/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2535 - accuracy: 0.9631 - val_loss: 7.1894 - val_accuracy: 0.8333\n",
      "Epoch 195/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2680 - accuracy: 0.9677 - val_loss: 5.2162 - val_accuracy: 0.8750\n",
      "Epoch 196/300\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.1559 - accuracy: 0.9792 - val_loss: 7.0173 - val_accuracy: 0.8167\n",
      "Epoch 197/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.2087 - accuracy: 0.9723 - val_loss: 6.2579 - val_accuracy: 0.8500\n",
      "Epoch 198/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.1364 - accuracy: 0.9808 - val_loss: 6.5754 - val_accuracy: 0.8417\n",
      "Epoch 199/300\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.1560 - accuracy: 0.9769 - val_loss: 4.6953 - val_accuracy: 0.8750\n",
      "Epoch 200/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2241 - accuracy: 0.9708 - val_loss: 5.5007 - val_accuracy: 0.8167\n",
      "Epoch 201/300\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.0988 - accuracy: 0.9815 - val_loss: 6.2402 - val_accuracy: 0.8083\n",
      "Epoch 202/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.3104 - accuracy: 0.9600 - val_loss: 5.6005 - val_accuracy: 0.8500\n",
      "Epoch 203/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.1726 - accuracy: 0.9762 - val_loss: 2.9389 - val_accuracy: 0.8917\n",
      "Epoch 204/300\n",
      "65/65 [==============================] - 11s 159ms/step - loss: 0.1214 - accuracy: 0.9769 - val_loss: 7.2223 - val_accuracy: 0.8333\n",
      "Epoch 205/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.1320 - accuracy: 0.9831 - val_loss: 8.1000 - val_accuracy: 0.8500\n",
      "Epoch 206/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2751 - accuracy: 0.9692 - val_loss: 6.8462 - val_accuracy: 0.8417\n",
      "Epoch 207/300\n",
      "65/65 [==============================] - 10s 147ms/step - loss: 0.1691 - accuracy: 0.9738 - val_loss: 7.8465 - val_accuracy: 0.8333\n",
      "Epoch 208/300\n",
      "65/65 [==============================] - 10s 152ms/step - loss: 0.1870 - accuracy: 0.9792 - val_loss: 9.3392 - val_accuracy: 0.8083\n",
      "Epoch 209/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1454 - accuracy: 0.9800 - val_loss: 8.3201 - val_accuracy: 0.8250\n",
      "Epoch 210/300\n",
      "65/65 [==============================] - 10s 155ms/step - loss: 0.2350 - accuracy: 0.9769 - val_loss: 7.3323 - val_accuracy: 0.8583\n",
      "Epoch 211/300\n",
      "65/65 [==============================] - 10s 151ms/step - loss: 0.1376 - accuracy: 0.9723 - val_loss: 7.2005 - val_accuracy: 0.8167\n",
      "Epoch 212/300\n",
      "65/65 [==============================] - 10s 145ms/step - loss: 0.1768 - accuracy: 0.9777 - val_loss: 6.5076 - val_accuracy: 0.8500\n",
      "Epoch 213/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2429 - accuracy: 0.9754 - val_loss: 9.1664 - val_accuracy: 0.7833\n",
      "Epoch 214/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.1771 - accuracy: 0.9754 - val_loss: 7.3309 - val_accuracy: 0.8583\n",
      "Epoch 215/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.2158 - accuracy: 0.9738 - val_loss: 7.8064 - val_accuracy: 0.8167\n",
      "Epoch 216/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.1593 - accuracy: 0.9769 - val_loss: 7.6487 - val_accuracy: 0.8667\n",
      "Epoch 217/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2086 - accuracy: 0.9746 - val_loss: 7.9605 - val_accuracy: 0.8833\n",
      "Epoch 218/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.2057 - accuracy: 0.9769 - val_loss: 8.8683 - val_accuracy: 0.8583\n",
      "Epoch 219/300\n",
      "65/65 [==============================] - 10s 144ms/step - loss: 0.1952 - accuracy: 0.9731 - val_loss: 6.9891 - val_accuracy: 0.8500\n",
      "Epoch 220/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1705 - accuracy: 0.9762 - val_loss: 8.0325 - val_accuracy: 0.8167\n",
      "Epoch 221/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2529 - accuracy: 0.9708 - val_loss: 8.1777 - val_accuracy: 0.8250\n",
      "Epoch 222/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2523 - accuracy: 0.9692 - val_loss: 7.4751 - val_accuracy: 0.8083\n",
      "Epoch 223/300\n",
      "65/65 [==============================] - 9s 146ms/step - loss: 0.1706 - accuracy: 0.9738 - val_loss: 6.7634 - val_accuracy: 0.8500\n",
      "Epoch 224/300\n",
      "65/65 [==============================] - 9s 143ms/step - loss: 0.2635 - accuracy: 0.9723 - val_loss: 9.6278 - val_accuracy: 0.7833\n",
      "Epoch 225/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1962 - accuracy: 0.9685 - val_loss: 8.0778 - val_accuracy: 0.8250\n",
      "Epoch 226/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.2570 - accuracy: 0.9654 - val_loss: 5.5866 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "65/65 [==============================] - 10s 147ms/step - loss: 0.1843 - accuracy: 0.9738 - val_loss: 6.2760 - val_accuracy: 0.8417\n",
      "Epoch 228/300\n",
      "65/65 [==============================] - 9s 143ms/step - loss: 0.1824 - accuracy: 0.9800 - val_loss: 8.1199 - val_accuracy: 0.8417\n",
      "Epoch 229/300\n",
      "65/65 [==============================] - 9s 146ms/step - loss: 0.1770 - accuracy: 0.9785 - val_loss: 6.8661 - val_accuracy: 0.8250\n",
      "Epoch 230/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2204 - accuracy: 0.9746 - val_loss: 7.9354 - val_accuracy: 0.8500\n",
      "Epoch 231/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2160 - accuracy: 0.9746 - val_loss: 7.7724 - val_accuracy: 0.8250\n",
      "Epoch 232/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1857 - accuracy: 0.9700 - val_loss: 8.1163 - val_accuracy: 0.8417\n",
      "Epoch 233/300\n",
      "65/65 [==============================] - 9s 143ms/step - loss: 0.2438 - accuracy: 0.9731 - val_loss: 7.9852 - val_accuracy: 0.8417\n",
      "Epoch 234/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1719 - accuracy: 0.9738 - val_loss: 7.7193 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2356 - accuracy: 0.9662 - val_loss: 8.7289 - val_accuracy: 0.8500\n",
      "Epoch 236/300\n",
      "65/65 [==============================] - 10s 147ms/step - loss: 0.2140 - accuracy: 0.9762 - val_loss: 8.0371 - val_accuracy: 0.8250\n",
      "Epoch 237/300\n",
      "65/65 [==============================] - 10s 145ms/step - loss: 0.1699 - accuracy: 0.9792 - val_loss: 6.4818 - val_accuracy: 0.8500\n",
      "Epoch 238/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.1480 - accuracy: 0.9785 - val_loss: 7.1027 - val_accuracy: 0.8500\n",
      "Epoch 239/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.1376 - accuracy: 0.9815 - val_loss: 7.7412 - val_accuracy: 0.8417\n",
      "Epoch 240/300\n",
      "65/65 [==============================] - 11s 160ms/step - loss: 0.1340 - accuracy: 0.9785 - val_loss: 7.5821 - val_accuracy: 0.8417\n",
      "Epoch 241/300\n",
      "65/65 [==============================] - 10s 155ms/step - loss: 0.1568 - accuracy: 0.9869 - val_loss: 7.9409 - val_accuracy: 0.8250\n",
      "Epoch 242/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.2521 - accuracy: 0.9738 - val_loss: 7.5737 - val_accuracy: 0.8417\n",
      "Epoch 243/300\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.1627 - accuracy: 0.9800 - val_loss: 7.6016 - val_accuracy: 0.8500\n",
      "Epoch 244/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.1742 - accuracy: 0.9831 - val_loss: 8.5277 - val_accuracy: 0.8083\n",
      "Epoch 245/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.1910 - accuracy: 0.9808 - val_loss: 7.2957 - val_accuracy: 0.8333\n",
      "Epoch 246/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.2055 - accuracy: 0.9831 - val_loss: 7.3900 - val_accuracy: 0.8417\n",
      "Epoch 247/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2107 - accuracy: 0.9731 - val_loss: 9.3470 - val_accuracy: 0.8417\n",
      "Epoch 248/300\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.1584 - accuracy: 0.9808 - val_loss: 7.6406 - val_accuracy: 0.8500\n",
      "Epoch 249/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.1489 - accuracy: 0.9831 - val_loss: 6.7888 - val_accuracy: 0.8750\n",
      "Epoch 250/300\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.1921 - accuracy: 0.9700 - val_loss: 7.1255 - val_accuracy: 0.8750\n",
      "Epoch 251/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.2257 - accuracy: 0.9692 - val_loss: 6.7777 - val_accuracy: 0.8250\n",
      "Epoch 252/300\n",
      "65/65 [==============================] - 11s 167ms/step - loss: 0.1300 - accuracy: 0.9746 - val_loss: 6.9906 - val_accuracy: 0.8667\n",
      "Epoch 253/300\n",
      "65/65 [==============================] - 10s 148ms/step - loss: 0.1830 - accuracy: 0.9777 - val_loss: 8.6303 - val_accuracy: 0.8333\n",
      "Epoch 254/300\n",
      "65/65 [==============================] - 10s 151ms/step - loss: 0.2657 - accuracy: 0.9708 - val_loss: 6.6299 - val_accuracy: 0.8583\n",
      "Epoch 255/300\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.1360 - accuracy: 0.9800 - val_loss: 7.8672 - val_accuracy: 0.8417\n",
      "Epoch 256/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.1977 - accuracy: 0.9754 - val_loss: 6.9333 - val_accuracy: 0.8833\n",
      "Epoch 257/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.1500 - accuracy: 0.9777 - val_loss: 6.4568 - val_accuracy: 0.8667\n",
      "Epoch 258/300\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.1675 - accuracy: 0.9785 - val_loss: 6.9062 - val_accuracy: 0.8500\n",
      "Epoch 259/300\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.1034 - accuracy: 0.9877 - val_loss: 5.7363 - val_accuracy: 0.8667\n",
      "Epoch 260/300\n",
      "65/65 [==============================] - 10s 150ms/step - loss: 0.2132 - accuracy: 0.9762 - val_loss: 5.8724 - val_accuracy: 0.8750\n",
      "Epoch 261/300\n",
      "65/65 [==============================] - 9s 146ms/step - loss: 0.1628 - accuracy: 0.9792 - val_loss: 8.2991 - val_accuracy: 0.8417\n",
      "Epoch 262/300\n",
      "65/65 [==============================] - 10s 152ms/step - loss: 0.1737 - accuracy: 0.9823 - val_loss: 7.6091 - val_accuracy: 0.8250\n",
      "Epoch 263/300\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 0.2287 - accuracy: 0.9754 - val_loss: 6.9204 - val_accuracy: 0.8500\n",
      "Epoch 264/300\n",
      "65/65 [==============================] - 11s 169ms/step - loss: 0.1461 - accuracy: 0.9800 - val_loss: 7.9449 - val_accuracy: 0.8417\n",
      "Epoch 265/300\n",
      "65/65 [==============================] - 11s 165ms/step - loss: 0.2757 - accuracy: 0.9769 - val_loss: 7.3312 - val_accuracy: 0.8667\n",
      "Epoch 266/300\n",
      "65/65 [==============================] - 10s 151ms/step - loss: 0.2122 - accuracy: 0.9708 - val_loss: 8.4856 - val_accuracy: 0.8417\n",
      "Epoch 267/300\n",
      "65/65 [==============================] - 11s 163ms/step - loss: 0.2668 - accuracy: 0.9746 - val_loss: 7.6009 - val_accuracy: 0.8500\n",
      "Epoch 268/300\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.2732 - accuracy: 0.9746 - val_loss: 7.8466 - val_accuracy: 0.8250\n",
      "Epoch 269/300\n",
      "65/65 [==============================] - 9s 143ms/step - loss: 0.1269 - accuracy: 0.9808 - val_loss: 6.4882 - val_accuracy: 0.8583\n",
      "Epoch 270/300\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.1921 - accuracy: 0.9746 - val_loss: 7.3771 - val_accuracy: 0.8250\n",
      "Epoch 271/300\n",
      "65/65 [==============================] - 11s 161ms/step - loss: 0.2227 - accuracy: 0.9723 - val_loss: 7.8384 - val_accuracy: 0.8417\n",
      "Epoch 272/300\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.2269 - accuracy: 0.9792 - val_loss: 7.2316 - val_accuracy: 0.8250\n",
      "Epoch 273/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1966 - accuracy: 0.9815 - val_loss: 6.9832 - val_accuracy: 0.8417\n",
      "Epoch 274/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2253 - accuracy: 0.9700 - val_loss: 6.5825 - val_accuracy: 0.8583\n",
      "Epoch 275/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2143 - accuracy: 0.9754 - val_loss: 7.2814 - val_accuracy: 0.8417\n",
      "Epoch 276/300\n",
      "65/65 [==============================] - 10s 145ms/step - loss: 0.1717 - accuracy: 0.9838 - val_loss: 7.6343 - val_accuracy: 0.8500\n",
      "Epoch 277/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1993 - accuracy: 0.9762 - val_loss: 7.6166 - val_accuracy: 0.8417\n",
      "Epoch 278/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.1773 - accuracy: 0.9731 - val_loss: 7.1502 - val_accuracy: 0.8583\n",
      "Epoch 279/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2087 - accuracy: 0.9708 - val_loss: 7.5016 - val_accuracy: 0.8167\n",
      "Epoch 280/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1925 - accuracy: 0.9746 - val_loss: 8.2650 - val_accuracy: 0.8333\n",
      "Epoch 281/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1724 - accuracy: 0.9762 - val_loss: 9.0529 - val_accuracy: 0.8583\n",
      "Epoch 282/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2543 - accuracy: 0.9715 - val_loss: 9.8183 - val_accuracy: 0.8333\n",
      "Epoch 283/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.1585 - accuracy: 0.9823 - val_loss: 10.1764 - val_accuracy: 0.8250\n",
      "Epoch 284/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.1271 - accuracy: 0.9823 - val_loss: 8.6528 - val_accuracy: 0.8583\n",
      "Epoch 285/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.1792 - accuracy: 0.9792 - val_loss: 9.0219 - val_accuracy: 0.8417\n",
      "Epoch 286/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2297 - accuracy: 0.9792 - val_loss: 7.1733 - val_accuracy: 0.8667\n",
      "Epoch 287/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2471 - accuracy: 0.9746 - val_loss: 7.4126 - val_accuracy: 0.8583\n",
      "Epoch 288/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.2424 - accuracy: 0.9777 - val_loss: 8.2906 - val_accuracy: 0.8500\n",
      "Epoch 289/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1416 - accuracy: 0.9823 - val_loss: 8.8486 - val_accuracy: 0.8083\n",
      "Epoch 290/300\n",
      "65/65 [==============================] - 10s 145ms/step - loss: 0.2428 - accuracy: 0.9792 - val_loss: 6.9912 - val_accuracy: 0.8667\n",
      "Epoch 291/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2087 - accuracy: 0.9746 - val_loss: 9.1892 - val_accuracy: 0.8250\n",
      "Epoch 292/300\n",
      "65/65 [==============================] - 9s 143ms/step - loss: 0.2044 - accuracy: 0.9785 - val_loss: 8.8024 - val_accuracy: 0.8667\n",
      "Epoch 293/300\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.1105 - accuracy: 0.9823 - val_loss: 7.6067 - val_accuracy: 0.8250\n",
      "Epoch 294/300\n",
      "65/65 [==============================] - 9s 146ms/step - loss: 0.2295 - accuracy: 0.9738 - val_loss: 7.6252 - val_accuracy: 0.8583\n",
      "Epoch 295/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.1597 - accuracy: 0.9800 - val_loss: 7.7477 - val_accuracy: 0.8500\n",
      "Epoch 296/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.1382 - accuracy: 0.9808 - val_loss: 8.3962 - val_accuracy: 0.8417\n",
      "Epoch 297/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.2370 - accuracy: 0.9785 - val_loss: 10.8284 - val_accuracy: 0.8250\n",
      "Epoch 298/300\n",
      "65/65 [==============================] - 9s 142ms/step - loss: 0.1798 - accuracy: 0.9792 - val_loss: 7.7662 - val_accuracy: 0.8833\n",
      "Epoch 299/300\n",
      "65/65 [==============================] - 9s 144ms/step - loss: 0.1418 - accuracy: 0.9808 - val_loss: 11.0310 - val_accuracy: 0.8083\n",
      "Epoch 300/300\n",
      "65/65 [==============================] - 10s 146ms/step - loss: 0.3304 - accuracy: 0.9723 - val_loss: 11.1998 - val_accuracy: 0.7917\n"
     ]
    }
   ],
   "source": [
    "input_shape = train_generator[0][0].shape[1:]\n",
    "output_shape = train_generator[0][1].shape[1]\n",
    "\n",
    "model3 = Sequential()\n",
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                    include_top=False,\n",
    "                    input_shape=input_shape)\n",
    "conv_base.trainable=False\n",
    "model3.add(conv_base)\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dense(output_shape, activation='softmax'))\n",
    "model3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# steps_per_epoch = len(X_train)//batch_size\n",
    "# validation_steps = len(X_valid)//batch_size\n",
    "steps_per_epoch = 1300//20\n",
    "history3 = model3.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=300,\n",
    "            # callbacks=[EarlyStopping(monitor='val_loss', patience=1)],\n",
    "            validation_data = valid_generator,\n",
    "            validation_steps = 130//20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('./model3(inceptionV3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# test = cv2.imread('./data/Img/char/train/upper/B/img012-005.png')\n",
    "test = cv2.imread('./data/Img/char/test/b.png')\n",
    "rm_img = test\n",
    "test = np.uint8(resize(rm_img, (150, 150), mode='constant') * 255)\n",
    "test = test.reshape(1, 150, 150, 3)\n",
    "pred = model3.predict(test)\n",
    "print(train_generator.class_indices)\n",
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "print(np.argmax(pred[[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A finish\n",
      "B finish\n",
      "C finish\n",
      "D finish\n",
      "E finish\n",
      "F finish\n",
      "G finish\n",
      "H finish\n",
      "I finish\n",
      "J finish\n",
      "K finish\n",
      "L finish\n",
      "M finish\n",
      "N finish\n",
      "O finish\n",
      "P finish\n",
      "Q finish\n",
      "R finish\n",
      "S finish\n",
      "T finish\n",
      "U finish\n",
      "V finish\n",
      "W finish\n",
      "X finish\n",
      "Y finish\n",
      "Z finish\n"
     ]
    }
   ],
   "source": [
    "char_list = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "for i in char_list:\n",
    "    # path = './data/else/char/train/upper/{}/'.format(i)\n",
    "    # org_path = './data/else/char/org/train/upper/{}/'.format(i)\n",
    "    path = './data/else/char/valid/upper/{}/'.format(i)\n",
    "    org_path = './data/else/char/org/valid/upper/{}/'.format(i)\n",
    "    file_list = os.listdir(org_path)\n",
    "    for j in file_list:\n",
    "        tmp = cv2.imread(org_path+j)\n",
    "        try:\n",
    "            tmp = pre_processing(tmp)\n",
    "        except:\n",
    "            print(org_path + j)\n",
    "        cv2.imwrite(path+j, tmp)\n",
    "    print('{} finish'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22127 images belonging to 26 classes.\n",
      "Found 2340 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir='./data/else/char/train/upper/'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=20, shear_range=0.1,\n",
    "    width_shift_range=0.1, height_shift_range=0.1,\n",
    "    zoom_range=0.1, horizontal_flip=False, fill_mode='nearest')\n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, target_size=(84, 84)\n",
    "#                     , color_mode='grayscale', batch_size=20, class_mode='categorical')\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150)\n",
    "                    , batch_size=64, class_mode='categorical')\n",
    "\n",
    "valid_dir='./data/else/char/valid/upper/'\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, target_size=(84, 84)\n",
    "#                     , color_mode='grayscale', batch_size=20, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(150, 150)\n",
    "                    , batch_size=64, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "128/345 [==========>...................] - ETA: 2:47 - loss: 5.7560 - accuracy: 0.5914"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\workspace\\Project\\test.ipynb  17\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=14'>15</a>\u001b[0m \u001b[39m# steps_per_epoch = len(X_train)//batch_size\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=15'>16</a>\u001b[0m \u001b[39m# validation_steps = len(X_valid)//batch_size\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=16'>17</a>\u001b[0m steps_per_epoch \u001b[39m=\u001b[39m \u001b[39m22127\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m64\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=17'>18</a>\u001b[0m history4 \u001b[39m=\u001b[39m model4\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=18'>19</a>\u001b[0m             train_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=19'>20</a>\u001b[0m             steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=20'>21</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=21'>22</a>\u001b[0m             \u001b[39m# callbacks=[EarlyStopping(monitor='val_loss', patience=1)],\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=22'>23</a>\u001b[0m             validation_data \u001b[39m=\u001b[39;49m valid_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/Project/test.ipynb#ch0000022?line=23'>24</a>\u001b[0m             validation_steps \u001b[39m=\u001b[39;49m \u001b[39m2340\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Users\\Pringles\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = train_generator[0][0].shape[1:]\n",
    "output_shape = train_generator[0][1].shape[1]\n",
    "\n",
    "model4 = Sequential()\n",
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                    include_top=False,\n",
    "                    input_shape=input_shape)\n",
    "conv_base.trainable=False\n",
    "model4.add(conv_base)\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(512, activation='relu'))\n",
    "model4.add(Dense(output_shape, activation='softmax'))\n",
    "model4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# steps_per_epoch = len(X_train)//batch_size\n",
    "# validation_steps = len(X_valid)//batch_size\n",
    "steps_per_epoch = 22127//64\n",
    "history4 = model4.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=300,\n",
    "            # callbacks=[EarlyStopping(monitor='val_loss', patience=1)],\n",
    "            validation_data = valid_generator,\n",
    "            validation_steps = 2340//64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d1fa453eb0bdc2ca16ccf6774a12892cf4b37282779183547db6d6597655ab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
